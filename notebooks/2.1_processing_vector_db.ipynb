{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Schema Data to Vector Database\n",
    "\n",
    "My initial thought was to build a model that checks for similarity between the prompt and the schema information. But in doing research it sounds like this could be simplified and expedited using a vector database through langchain. We could then query the tables (with metadata) based on the question and return the documents that are most closely related. With this, we'll try to all be bundled into langchain. woohoo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "I'll test the structure of the data - breaking it out into a way to load into \"documents\"\n",
    "\n",
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in json\n",
    "path = '../data/interim/'\n",
    "\n",
    "with open(path+'schema_info.json', \"r\") as f:\n",
    "    schema_info = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'custid'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_info[0]['columns'][0]['c_name']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to try to create a \"document\" for each table with metadata of the schema, table, and a list of columns. I don't know if the column type would be helpful to the model, so I may leave just to try, but also don't want to add useless details to storage. I'll leave them out, but comment out the raw code that will work to pull in all the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written_by {'schema': 'imdb', 'table': 'written_by', 'columns': ['id', 'msid', 'wid']}\n"
     ]
    }
   ],
   "source": [
    "for table in schema_info:\n",
    "    doc = table['table']\n",
    "    cols = table['columns']\n",
    "    col_names = [column['c_name'] for column in cols]\n",
    "    metadata={\n",
    "        'schema': table['schema'],\n",
    "        'table': table['table'],\n",
    "        'columns': c_names,\n",
    "    }\n",
    "\n",
    "print(doc, metadata)\n",
    "\n",
    "\n",
    "###code to return full column_info in metadata\n",
    "#for table in schema_info:\n",
    "#    doc = table['table']\n",
    "#    metadata={\n",
    "#        'schema': table['schema'],\n",
    "#        'table': table['table'],\n",
    "#        'columns': json.dumps(table['columns']),\n",
    "#    }\n",
    "\n",
    "#print(doc, metadata)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup langchain Document\n",
    "\n",
    "Documents are just a piece of text that you can optionalliy add metadata too. Straighforward, but they allow for using model and databases with langchain. They have a module for setting up documents: \"Document\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    Document(\n",
    "        page_content=f\"Table: {simple_meta['table']}\",\n",
    "        metadata={\n",
    "            'schema': simple_meta['schema'],\n",
    "            'table': simple_meta['table'],\n",
    "            'columns': [col['c_name'] for col in simple_meta['columns']]\n",
    "        },\n",
    "    )\n",
    "    for simple_meta in schema_info\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Table: ACCOUNTS', metadata={'schema': 'small_bank_1', 'table': 'ACCOUNTS', 'columns': ['custid', 'name']}),\n",
       " Document(page_content='Table: AREA_CODE_STATE', metadata={'schema': 'voter_1', 'table': 'AREA_CODE_STATE', 'columns': ['area_code', 'state']}),\n",
       " Document(page_content='Table: Acceptance', metadata={'schema': 'workshop_paper', 'table': 'Acceptance', 'columns': ['Submission_ID', 'Workshop_ID', 'Result']})]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text2sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
