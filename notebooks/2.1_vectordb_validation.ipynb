{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Database Validation\n",
    "\n",
    "I key necessity of this application is to correctly identify where to go get the answers to the question. This can be fairly simple with a precise user input question like \"pull from x schema\" or more unique keywords. But it can also be very tough. In the first version of this, I have a pure vectordb similarity search. I want to test how accurately this get the correct schema in the top 1 and top 3. If it's not satisfactory - I want to then move onto testing other options or ways to supplement it.\n",
    "\n",
    "I've seen people point directly to the correct schema (since it's provided by the database), but I wanted to add this extra complexity because in my day-to-day I don't usually know exactly where to go for something.\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test First VectorDB - Schema & Table\n",
    "### Point to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup embeddings using HuggingFace and the directory location\n",
    "embeddings  = HuggingFaceEmbeddings()\n",
    "persist_dir = '../data/processed/chromadb/schema-table-split'\n",
    "\n",
    "# load from disk\n",
    "vectordb = Chroma(persist_directory=persist_dir, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull in Training Data to Validate Against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'department_management'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load json with question and Taget Schema\n",
    "path = '../data/raw/spider/'\n",
    "\n",
    "with open(path+'train_spider.json', \"r\") as f:\n",
    "    spi_train = json.load(f)\n",
    "\n",
    "spi_train[0]['db_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>target_schema</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many heads of the departments are older th...</td>\n",
       "      <td>department_management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>List the name, born state and age of the heads...</td>\n",
       "      <td>department_management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>List the creation year, name and budget of eac...</td>\n",
       "      <td>department_management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the maximum and minimum budget of the...</td>\n",
       "      <td>department_management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the average number of employees of the...</td>\n",
       "      <td>department_management</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question          target_schema\n",
       "0  How many heads of the departments are older th...  department_management\n",
       "1  List the name, born state and age of the heads...  department_management\n",
       "2  List the creation year, name and budget of eac...  department_management\n",
       "3  What are the maximum and minimum budget of the...  department_management\n",
       "4  What is the average number of employees of the...  department_management"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert json into a pandas dataframe and update the column names\n",
    "training_df = pd.json_normalize(spi_train)[['question','db_id']]\n",
    "\n",
    "training_df = training_df.rename(columns={'db_id': 'target_schema'})\n",
    "\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Loop to Test each of these questions against the vector db."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This could take a while. Make sure to do some tests. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write function for similarity search to apply to each row of the dataframe\n",
    "def sim_search(question, vector_db, k=3):\n",
    "    top_results = vector_db.similarity_search(question, k=k)\n",
    "    top_matches = list(dict.fromkeys([doc.metadata['schema'] for doc in top_results]))\n",
    "\n",
    "    return top_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>target_schema</th>\n",
       "      <th>top_three_match</th>\n",
       "      <th>top_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many heads of the departments are older th...</td>\n",
       "      <td>department_management</td>\n",
       "      <td>[department_management, hr_1]</td>\n",
       "      <td>department_management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>List the name, born state and age of the heads...</td>\n",
       "      <td>department_management</td>\n",
       "      <td>[department_management, local_govt_in_alabama]</td>\n",
       "      <td>department_management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>List the creation year, name and budget of eac...</td>\n",
       "      <td>department_management</td>\n",
       "      <td>[department_management, e_government]</td>\n",
       "      <td>department_management</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question          target_schema  \\\n",
       "0  How many heads of the departments are older th...  department_management   \n",
       "1  List the name, born state and age of the heads...  department_management   \n",
       "2  List the creation year, name and budget of eac...  department_management   \n",
       "\n",
       "                                  top_three_match              top_match  \n",
       "0                   [department_management, hr_1]  department_management  \n",
       "1  [department_management, local_govt_in_alabama]  department_management  \n",
       "2           [department_management, e_government]  department_management  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test function on 10 row df\n",
    "df_test = training_df[['question','target_schema']].head(10)\n",
    "\n",
    "df_test['top_three_match'] = df_test.apply(lambda x: sim_search(x['question'], k=3), axis=1)\n",
    "df_test['top_match'] = df_test.apply(lambda x: x['top_three_match'][0], axis=1)\n",
    "\n",
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this function to create two new fields in our training dataframe: top result and top 3 results (unique)\n",
    "training_df['top_three_match_unique'] = training_df.apply(lambda x: sim_search(x['question'], k=3), axis=1)\n",
    "training_df['top_one_match'] = training_df.apply(lambda x: x['top_three_match_unique'][0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>target_schema</th>\n",
       "      <th>top_three_match_unique</th>\n",
       "      <th>top_one_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many heads of the departments are older th...</td>\n",
       "      <td>department_management</td>\n",
       "      <td>[department_management, hr_1]</td>\n",
       "      <td>department_management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>List the name, born state and age of the heads...</td>\n",
       "      <td>department_management</td>\n",
       "      <td>[department_management, local_govt_in_alabama]</td>\n",
       "      <td>department_management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>List the creation year, name and budget of eac...</td>\n",
       "      <td>department_management</td>\n",
       "      <td>[department_management, e_government]</td>\n",
       "      <td>department_management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the maximum and minimum budget of the...</td>\n",
       "      <td>department_management</td>\n",
       "      <td>[department_management, e_government]</td>\n",
       "      <td>department_management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the average number of employees of the...</td>\n",
       "      <td>department_management</td>\n",
       "      <td>[department_store, department_management, hr_1]</td>\n",
       "      <td>department_store</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question          target_schema  \\\n",
       "0  How many heads of the departments are older th...  department_management   \n",
       "1  List the name, born state and age of the heads...  department_management   \n",
       "2  List the creation year, name and budget of eac...  department_management   \n",
       "3  What are the maximum and minimum budget of the...  department_management   \n",
       "4  What is the average number of employees of the...  department_management   \n",
       "\n",
       "                            top_three_match_unique          top_one_match  \n",
       "0                    [department_management, hr_1]  department_management  \n",
       "1   [department_management, local_govt_in_alabama]  department_management  \n",
       "2            [department_management, e_government]  department_management  \n",
       "3            [department_management, e_government]  department_management  \n",
       "4  [department_store, department_management, hr_1]       department_store  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column that flag 1-0 if the schema matches the top 1.\n",
    "training_df['top_one_is_match'] = np.where(training_df['target_schema'] == training_df['top_one_match'], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now for the top 3 unique\n",
    "#define a function for this\n",
    "def is_schema_in_top_three(row):\n",
    "    if row['target_schema'] in row['top_three_match_unique']:\n",
    "        boo = 1\n",
    "    else:\n",
    "        boo = 0\n",
    "    return boo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each row using 'apply' and store the result in a new column 'is_in_top_three'\n",
    "training_df['top_three_is_match'] = training_df.apply(is_schema_in_top_three, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>target_schema</th>\n",
       "      <th>top_three_match_unique</th>\n",
       "      <th>top_one_match</th>\n",
       "      <th>top_one_is_match</th>\n",
       "      <th>top_three_is_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many heads of the departments are older th...</td>\n",
       "      <td>department_management</td>\n",
       "      <td>[department_management, hr_1]</td>\n",
       "      <td>department_management</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>List the name, born state and age of the heads...</td>\n",
       "      <td>department_management</td>\n",
       "      <td>[department_management, local_govt_in_alabama]</td>\n",
       "      <td>department_management</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>List the creation year, name and budget of eac...</td>\n",
       "      <td>department_management</td>\n",
       "      <td>[department_management, e_government]</td>\n",
       "      <td>department_management</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the maximum and minimum budget of the...</td>\n",
       "      <td>department_management</td>\n",
       "      <td>[department_management, e_government]</td>\n",
       "      <td>department_management</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the average number of employees of the...</td>\n",
       "      <td>department_management</td>\n",
       "      <td>[department_store, department_management, hr_1]</td>\n",
       "      <td>department_store</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What are the names of the heads who are born o...</td>\n",
       "      <td>department_management</td>\n",
       "      <td>[voter_1, election, party_people]</td>\n",
       "      <td>voter_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What are the distinct creation years of the de...</td>\n",
       "      <td>department_management</td>\n",
       "      <td>[local_govt_in_alabama]</td>\n",
       "      <td>local_govt_in_alabama</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What are the names of the states where at leas...</td>\n",
       "      <td>department_management</td>\n",
       "      <td>[geo, world_1, voter_1]</td>\n",
       "      <td>geo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>In which year were most departments established?</td>\n",
       "      <td>department_management</td>\n",
       "      <td>[department_management, hr_1]</td>\n",
       "      <td>department_management</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Show the name and number of employees for the ...</td>\n",
       "      <td>department_management</td>\n",
       "      <td>[department_management]</td>\n",
       "      <td>department_management</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question          target_schema  \\\n",
       "0  How many heads of the departments are older th...  department_management   \n",
       "1  List the name, born state and age of the heads...  department_management   \n",
       "2  List the creation year, name and budget of eac...  department_management   \n",
       "3  What are the maximum and minimum budget of the...  department_management   \n",
       "4  What is the average number of employees of the...  department_management   \n",
       "5  What are the names of the heads who are born o...  department_management   \n",
       "6  What are the distinct creation years of the de...  department_management   \n",
       "7  What are the names of the states where at leas...  department_management   \n",
       "8   In which year were most departments established?  department_management   \n",
       "9  Show the name and number of employees for the ...  department_management   \n",
       "\n",
       "                            top_three_match_unique          top_one_match  \\\n",
       "0                    [department_management, hr_1]  department_management   \n",
       "1   [department_management, local_govt_in_alabama]  department_management   \n",
       "2            [department_management, e_government]  department_management   \n",
       "3            [department_management, e_government]  department_management   \n",
       "4  [department_store, department_management, hr_1]       department_store   \n",
       "5                [voter_1, election, party_people]                voter_1   \n",
       "6                          [local_govt_in_alabama]  local_govt_in_alabama   \n",
       "7                          [geo, world_1, voter_1]                    geo   \n",
       "8                    [department_management, hr_1]  department_management   \n",
       "9                          [department_management]  department_management   \n",
       "\n",
       "   top_one_is_match  top_three_is_match  \n",
       "0                 1                   1  \n",
       "1                 1                   1  \n",
       "2                 1                   1  \n",
       "3                 1                   1  \n",
       "4                 0                   1  \n",
       "5                 0                   0  \n",
       "6                 0                   0  \n",
       "7                 0                   0  \n",
       "8                 1                   1  \n",
       "9                 1                   1  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "training_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Results\n",
    "\n",
    "Look at pure accuracy - what % of the total match for the top 1 and top 3 unique?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total rows\n",
    "tot_q = training_df.shape[0]\n",
    "\n",
    "#top 1 match\n",
    "top_one_match = training_df['top_one_is_match'].sum()\n",
    "\n",
    "#top 3 match\n",
    "top_three_match = training_df['top_three_is_match'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st result matches: 42.13%\n",
      "Top 3 results match: 57.00%\n"
     ]
    }
   ],
   "source": [
    "print(f\"1st result matches: {top_one_match/tot_q:.2%}\")\n",
    "print(f\"Top 3 results match: {top_three_match/tot_q:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've got a lot of room for improvement! But at least the testing method works.\n",
    "\n",
    "I think I want to try loading more metadata about the schema - tables. And using some entity extraction on the question, combining both steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New VectorDB Test\n",
    "\n",
    "I create a new vectordatabase loading the table info with the page contents include the schema and table again, but now including the columns and table create statements.\n",
    "\n",
    "I'll run our same process on this new DB. And I'll write functions that can hopefully only need minor tweaks to repeat this multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write updated function to give option for which search method\n",
    "def sim_search(question, vector_db, method=\"cosine\", k=3):\n",
    "    if method == \"cosine\":\n",
    "        top_results = vector_db.similarity_search(question, k=k)\n",
    "        top_matches = list(dict.fromkeys([doc.metadata['schema'] for doc in top_results]))\n",
    "    elif method == \"mmr\":\n",
    "        retriever = vector_db.as_retriever(search_type=\"mmr\")\n",
    "        top_results = retriever.get_relevant_documents(question)[:3]\n",
    "        top_matches = list(dict.fromkeys([doc.metadata['schema'] for doc in top_results]))\n",
    "\n",
    "    return top_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_search_test(json_file, vectordb, method=\"cosine\"):\n",
    "    \"\"\"Create a quick and dirty function to test accuracy multiple times.\"\"\"\n",
    "    df = pd.json_normalize(json_file)[['question','db_id']]\n",
    "\n",
    "    df = df.rename(columns={'db_id': 'target_schema'})\n",
    "\n",
    "    #Use this function to create two new fields in our training dataframe: top result and top 3 results (unique)\n",
    "    df['top_three_match_unique'] = df.apply(lambda x: sim_search(x['question'], vector_db=vectordb, method=method, k=3), axis=1)\n",
    "    df['top_one_match'] = df.apply(lambda x: x['top_three_match_unique'][0], axis=1)\n",
    "\n",
    "    df['top_one_is_match'] = np.where(df['target_schema'] == df['top_one_match'], 1, 0)\n",
    "\n",
    "    df['top_three_is_match'] = df.apply(is_schema_in_top_three, axis=1)\n",
    "\n",
    "    #total rows\n",
    "    tot_q = df.shape[0]\n",
    "    #top 1 match\n",
    "    top_one_match = df['top_one_is_match'].sum()\n",
    "    #top 3 match\n",
    "    top_three_match = df['top_three_is_match'].sum()\n",
    "\n",
    "    print(f\"1st result matches: {top_one_match/tot_q:.2%}\")\n",
    "    print(f\"Top 3 results match: {top_three_match/tot_q:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test schema-table info vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup embeddings using HuggingFace and the directory location\n",
    "embeddings2  = HuggingFaceEmbeddings()\n",
    "persist_dir2 = '../data/processed/chromadb/schema-table-info'\n",
    "\n",
    "# load from disk\n",
    "vectordb_2 = Chroma(persist_directory=persist_dir2, embedding_function=embeddings2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st result matches: 54.91%\n",
      "Top 3 results match: 70.83%\n"
     ]
    }
   ],
   "source": [
    "###commenting out since this runs slow###\n",
    "\n",
    "#sim_search_test(json_file=spi_train, vectordb=vectordb_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st result matches: 57.04%\n",
      "Top 3 results match: 68.44%\n"
     ]
    }
   ],
   "source": [
    "###commenting out since this runs slow###\n",
    "\n",
    "#test with MMR Method\n",
    "#sim_search_test(json_file=spi_train, vectordb=vectordb_2, method=\"mmr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. Both are better than the old version. But the mmr is slightly better on primary matches, slightly worse on top 3 matches.\n",
    "\n",
    "I'll keep working on improving the score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Method Test\n",
    "\n",
    "This one I worry will be too slow, so I may do it on a sampling of the questions. First I need to do my uploads and create function to recurringly call to LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain import HuggingFaceHub\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create prompt contents\n",
    "extract_prompt = \"\"\"question: How many teams are there?\n",
    "response: team\n",
    "\n",
    "question: What user spent the most money in March?\n",
    "response: user, money\n",
    "\n",
    "question: What is the name of the instructor who advises the student with the greatest number of total credits?\n",
    "response: instructor, advisor, student, credits\n",
    "\"\"\"\n",
    "\n",
    "instruction = \"\"\"\n",
    "For a given question, determine the keywords for determining what tables should be used to write a SQL query to answer the question.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get api key\n",
    "load_dotenv()\n",
    "hf_api_token = os.getenv('hf_token')\n",
    "\n",
    "#add path to HF repo\n",
    "repo_id = 'tiiuae/falcon-7b-instruct'\n",
    "\n",
    "#establish llm model\n",
    "llm = HuggingFaceHub(repo_id=repo_id, huggingfacehub_api_token=hf_api_token, model_kwargs={\"temperature\": .005, \"max_length\": 512})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function\n",
    "def sim_search_llm(question, vector_db, method=\"cosine\", k=3, instruction=instruction, extract_prompt=extract_prompt):\n",
    "    \n",
    "    entity_extr_prompt = PromptTemplate(\n",
    "    input_variables=[],\n",
    "    template = \n",
    "        instruction\n",
    "        + \"\\nHere are are three question/response examples: \"\n",
    "        + extract_prompt\n",
    "        + \"\\n\\nquestion: \"\n",
    "        + question\n",
    "        + \"\\nresponse:\"\n",
    "    )\n",
    "\n",
    "    #create chain\n",
    "    chain = LLMChain(llm=llm, prompt=entity_extr_prompt, verbose=False)\n",
    "\n",
    "    #predict\n",
    "    results= chain.predict() #run llm\n",
    "\n",
    "    #run simsearch on predicted keywords\n",
    "    top_results = vector_db.similarity_search(results, k=k)\n",
    "    top_matches = list(dict.fromkeys([doc.metadata['schema'] for doc in top_results]))\n",
    "\n",
    "    return top_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull sample of questions and save to pandas df => start with 50 samples\n",
    "df_sample = training_df.sample(n=50, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function for testing these 50 sample questions using our llm method\n",
    "def sim_search_llm_test(df, vectordb):\n",
    "    \"\"\"Create a quick and dirty function to test accuracy multiple times.\"\"\"\n",
    "    \n",
    "    #Use this function to create two new fields in our training dataframe: top result and top 3 results (unique)\n",
    "    df['top_three_match_unique'] = df.apply(lambda x: sim_search_llm(x['question'], vector_db=vectordb, k=3), axis=1)\n",
    "    df['top_one_match'] = df.apply(lambda x: x['top_three_match_unique'][0], axis=1)\n",
    "\n",
    "    df['top_one_is_match'] = np.where(df['target_schema'] == df['top_one_match'], 1, 0)\n",
    "\n",
    "    df['top_three_is_match'] = df.apply(is_schema_in_top_three, axis=1)\n",
    "\n",
    "    #total rows\n",
    "    tot_q = df.shape[0]\n",
    "    #top 1 match\n",
    "    top_one_match = df['top_one_is_match'].sum()\n",
    "    #top 3 match\n",
    "    top_three_match = df['top_three_is_match'].sum()\n",
    "\n",
    "    print(f\"1st result matches: {top_one_match/tot_q:.2%}\")\n",
    "    print(f\"Top 3 results match: {top_three_match/tot_q:.2%}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st result matches: 46.00%\n",
      "Top 3 results match: 60.00%\n"
     ]
    }
   ],
   "source": [
    "ss_test_df = sim_search_llm_test(df=df_sample, vectordb=vectordb_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>target_schema</th>\n",
       "      <th>top_three_match_unique</th>\n",
       "      <th>top_one_match</th>\n",
       "      <th>top_one_is_match</th>\n",
       "      <th>top_three_is_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>What are the different driver ids and national...</td>\n",
       "      <td>formula_1</td>\n",
       "      <td>[formula_1]</td>\n",
       "      <td>formula_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6835</th>\n",
       "      <td>Find the names of the top 10 airlines that ope...</td>\n",
       "      <td>flight_4</td>\n",
       "      <td>[flight_4, flight_2]</td>\n",
       "      <td>flight_4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3620</th>\n",
       "      <td>What are the top 3 artists with the largest nu...</td>\n",
       "      <td>music_1</td>\n",
       "      <td>[music_1, chinook_1, music_2]</td>\n",
       "      <td>music_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6717</th>\n",
       "      <td>What ranks do we have for faculty?</td>\n",
       "      <td>activity_1</td>\n",
       "      <td>[film_rank, sports_competition, farm]</td>\n",
       "      <td>film_rank</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3752</th>\n",
       "      <td>Find the names of programs that are never broa...</td>\n",
       "      <td>program_share</td>\n",
       "      <td>[tracking_software_problems, browser_web]</td>\n",
       "      <td>tracking_software_problems</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  target_schema  \\\n",
       "2164  What are the different driver ids and national...      formula_1   \n",
       "6835  Find the names of the top 10 airlines that ope...       flight_4   \n",
       "3620  What are the top 3 artists with the largest nu...        music_1   \n",
       "6717                 What ranks do we have for faculty?     activity_1   \n",
       "3752  Find the names of programs that are never broa...  program_share   \n",
       "\n",
       "                         top_three_match_unique               top_one_match  \\\n",
       "2164                                [formula_1]                   formula_1   \n",
       "6835                       [flight_4, flight_2]                    flight_4   \n",
       "3620              [music_1, chinook_1, music_2]                     music_1   \n",
       "6717      [film_rank, sports_competition, farm]                   film_rank   \n",
       "3752  [tracking_software_problems, browser_web]  tracking_software_problems   \n",
       "\n",
       "      top_one_is_match  top_three_is_match  \n",
       "2164                 1                   1  \n",
       "6835                 1                   1  \n",
       "3620                 1                   1  \n",
       "6717                 0                   0  \n",
       "3752                 0                   0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Test - No Table Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup embeddings using HuggingFace and the directory location\n",
    "embeddings  = HuggingFaceEmbeddings()\n",
    "persist_dir3 = '../data/processed/chromadb/sch-tab-col'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from disk\n",
    "vectordb_3 = Chroma(persist_directory=persist_dir3, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st result matches: 53.13%\n",
      "Top 3 results match: 68.23%\n"
     ]
    }
   ],
   "source": [
    "sim_search_test(json_file=spi_train, vectordb=vectordb_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "Having the table info looks like it gives the results some slight improvement. I'll go with that - probably changing some of the naming and building out the method in a .py file.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Look at which databases perform the worst and strategize ways to improve. Possibily end up trying to automate the schema pull from the sqlite databases themselves. Instead of relying on the provided schema info. Consolidating that schema info would just be an extra step in the real world."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text2sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
