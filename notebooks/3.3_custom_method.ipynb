{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Agent\n",
    "\n",
    "I had limited success with the built-in functions, so here I test and build out a custom method, which is really a combination of tweaked langchain functions.\n",
    "\n",
    "I think part of this could be more specialized schema and table extraction, but for now I test with my same question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2023-08-01T00:56:17.968275-07:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.4\n",
      "IPython version      : 8.14.0\n",
      "\n",
      "Compiler    : Clang 15.0.7 \n",
      "OS          : Darwin\n",
      "Release     : 22.5.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from watermark import watermark\n",
    "print(watermark())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain import HuggingFaceHub, SQLDatabase\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set this to false to get rid of warning\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup query\n",
    "We'll use this to input into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How many heads of the departments are older than 56?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Target Tables from Vectordb\n",
    "\n",
    "Load in the top 3 results and save just the unique schemas to a set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup embeddings using HuggingFace and the directory location\n",
    "embeddings  = HuggingFaceEmbeddings()\n",
    "persist_dir = '../data/processed/chromadb/schema-table-info'\n",
    "\n",
    "# load from disk\n",
    "vectordb = Chroma(persist_directory=persist_dir, embedding_function=embeddings)\n",
    "\n",
    "#run similarity search\n",
    "top_results = vectordb.similarity_search(question, k=3) #just return the top for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\\nSchema: department_management\\nTable: head\\nColumns: [\"head_ID\", \"name\", \"born_state\", \"age\"]\\nDDL:\\n    \\nCREATE TABLE head (\\n\\t\"head_ID\" INTEGER, \\n\\tname TEXT, \\n\\tborn_state TEXT, \\n\\tage REAL, \\n\\tPRIMARY KEY (\"head_ID\")\\n)\\n\\n/*\\n3 rows from head table:\\nhead_ID\\tname\\tborn_state\\tage\\n1\\tTiger Woods\\tAlabama\\t67.0\\n2\\tSergio García\\tCalifornia\\t68.0\\n3\\tK. J. Choi\\tAlabama\\t69.0\\n*/\\n', metadata={'schema': 'department_management', 'table': 'head', 'columns': '[\"head_ID\", \"name\", \"born_state\", \"age\"]'}),\n",
       " Document(page_content='\\nSchema: hr_1\\nTable: departments\\nColumns: [\"DEPARTMENT_ID\", \"DEPARTMENT_NAME\", \"MANAGER_ID\", \"LOCATION_ID\"]\\nDDL:\\n    \\nCREATE TABLE departments (\\n\\t\"DEPARTMENT_ID\" DECIMAL(4, 0) DEFAULT \\'0\\' NOT NULL, \\n\\t\"DEPARTMENT_NAME\" VARCHAR(30) NOT NULL, \\n\\t\"MANAGER_ID\" DECIMAL(6, 0) DEFAULT NULL, \\n\\t\"LOCATION_ID\" DECIMAL(4, 0) DEFAULT NULL, \\n\\tPRIMARY KEY (\"DEPARTMENT_ID\")\\n)\\n\\n/*\\n3 rows from departments table:\\nDEPARTMENT_ID\\tDEPARTMENT_NAME\\tMANAGER_ID\\tLOCATION_ID\\n10\\tAdministration\\t200\\t1700\\n20\\tMarketing\\t201\\t1800\\n30\\tPurchasing\\t114\\t1700\\n*/\\n', metadata={'schema': 'hr_1', 'table': 'departments', 'columns': '[\"DEPARTMENT_ID\", \"DEPARTMENT_NAME\", \"MANAGER_ID\", \"LOCATION_ID\"]'}),\n",
       " Document(page_content='\\nSchema: company_1\\nTable: department\\nColumns: [\"Dname\", \"Dnumber\", \"Mgr_ssn\", \"Mgr_start_date\"]\\nDDL:\\n    \\nCREATE TABLE department (\\n\\t\"Dname\" TEXT, \\n\\t\"Dnumber\" INTEGER, \\n\\t\"Mgr_ssn\" INTEGER, \\n\\t\"Mgr_start_date\" TEXT, \\n\\tPRIMARY KEY (\"Dnumber\")\\n)\\n\\n/*\\n3 rows from department table:\\nDname\\tDnumber\\tMgr_ssn\\tMgr_start_date\\nHeadquarters\\t1\\t888665555\\t1981-06-19\\nAdministration\\t4\\t987654321\\t1995-01-01\\nResearch\\t5\\t333445555\\t1988-05-22\\n*/\\n', metadata={'schema': 'company_1', 'table': 'department', 'columns': '[\"Dname\", \"Dnumber\", \"Mgr_ssn\", \"Mgr_start_date\"]'})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'department_management'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_results[0].metadata['schema']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Target Schemas\n",
    "\n",
    "I want to get a unique list of schemas from the top 3 documents returned by the vecotr database similarity search - and make sure they stay in order of importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['department_management', 'hr_1', 'company_1']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try in a standard list with dict.fromkeys\n",
    "tgt_list = list(dict.fromkeys([doc.metadata['schema'] for doc in top_results]))\n",
    "\n",
    "tgt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'department_management'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool - Query for Schema Information\n",
    "Use the langchain SQLDatabase class to get all the information about the schema. I think I also want to use the most likely columns returned to sort and prioritize how the tables are fed into the llm.\n",
    "\n",
    "I could load in the sql_query tools from langchain.tools, but I want to tweek things a little bit, especially in the order. I could come back to this later if it does simplify things and my way doesn't make the outcome any better.\n",
    "\n",
    "#### Point to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_filepath = '../data/processed/db/'\n",
    "db_filename = list(target_schemas)[0] + '.sqlite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#point to database\n",
    "base_dir = os.path.dirname(os.path.abspath(db_filepath+db_filename)) #get the full path within the device\n",
    "db_path = os.path.join(base_dir, db_filename) #combine with filename to get db_path\n",
    "db = SQLDatabase.from_uri(\"sqlite:///\" + db_path) #connect via the lanchain method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set table sorting and then pull tables names using langchain\n",
    "\n",
    "In testing prompts in the last 3 notebooks I noticed that loading in all the tables without context of which table the similarity search even caused some troubles for ChatGPT. This got me thinking that even just putting the tables in order of how the similarity search ranked them compared to our question could be a useful change to the prompt. So the next steps I take are to to pull in the potential targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['head']\n"
     ]
    }
   ],
   "source": [
    "#pull the table names from the vector query so we can have them in order of similarity to the question.\n",
    "table_sorting = set()\n",
    "for doc in top_results:\n",
    "    schema = doc.metadata['schema']\n",
    "    if schema == 'department_management':\n",
    "        table_name = doc.metadata['table']\n",
    "        table_sorting.add(table_name)\n",
    "table_sorting = list(table_sorting)\n",
    "print(table_sorting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could just use this one returned table, but for this version of the app I will just use this set to sort all of the columns in the table to feed to the LLM with the \"set\" columns prioritized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['head', 'department', 'management']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get tables names\n",
    "table_names = db.get_usable_table_names()\n",
    "\n",
    "#sort by the results of our vector query to load the most likely table in first. Not sure if this will make a difference, but can't imagine it would hurt.\n",
    "priority_tables = sorted(table_names, key=lambda x: (table_sorting.index(x) if x in table_sorting else float('inf'), table_names.index(x)))\n",
    "\n",
    "priority_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get SQL Dialect\n",
    "\n",
    "Using the langchain class again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sqlite'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_dialect = db.dialect\n",
    "\n",
    "sql_dialect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get table info\n",
    "\n",
    "You can do this for all tables in the database automatically with the function, but I want to continue trying to order these by likelihood of being related to the question. So I'll do this in a loop.\n",
    "\n",
    "This gives the full create statement and 3 sample rows, which I think will be a great start. And really gets us to where the Chain does for adding to the prompt template. I'll also combine this with the table name at the start of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDL for the head table:\n",
      "CREATE TABLE head (\n",
      "\t\"head_ID\" INTEGER, \n",
      "\tname TEXT, \n",
      "\tborn_state TEXT, \n",
      "\tage REAL, \n",
      "\tPRIMARY KEY (\"head_ID\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from head table:\n",
      "head_ID\tname\tborn_state\tage\n",
      "1\tTiger Woods\tAlabama\t67.0\n",
      "2\tSergio García\tCalifornia\t68.0\n",
      "3\tK. J. Choi\tAlabama\t69.0\n",
      "*/\n",
      "\n",
      "DDL for the department table:\n",
      "CREATE TABLE department (\n",
      "\t\"Department_ID\" INTEGER, \n",
      "\t\"Name\" TEXT, \n",
      "\t\"Creation\" TEXT, \n",
      "\t\"Ranking\" INTEGER, \n",
      "\t\"Budget_in_Billions\" REAL, \n",
      "\t\"Num_Employees\" REAL, \n",
      "\tPRIMARY KEY (\"Department_ID\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from department table:\n",
      "Department_ID\tName\tCreation\tRanking\tBudget_in_Billions\tNum_Employees\n",
      "1\tState\t1789\t1\t9.96\t30266.0\n",
      "2\tTreasury\t1789\t2\t11.1\t115897.0\n",
      "3\tDefense\t1947\t3\t439.3\t3000000.0\n",
      "*/\n",
      "\n",
      "DDL for the management table:\n",
      "CREATE TABLE management (\n",
      "\t\"department_ID\" INTEGER, \n",
      "\t\"head_ID\" INTEGER, \n",
      "\ttemporary_acting TEXT, \n",
      "\tPRIMARY KEY (\"department_ID\", \"head_ID\"), \n",
      "\tFOREIGN KEY(\"head_ID\") REFERENCES head (\"head_ID\"), \n",
      "\tFOREIGN KEY(\"department_ID\") REFERENCES department (\"Department_ID\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from management table:\n",
      "department_ID\thead_ID\ttemporary_acting\n",
      "2\t5\tYes\n",
      "15\t4\tYes\n",
      "2\t6\tYes\n",
      "*/\n"
     ]
    }
   ],
   "source": [
    "table_info = []\n",
    "for table in priority_tables:\n",
    "    table_name = table\n",
    "    info = db.get_table_info(table_names=[table])\n",
    "    table_info.append('DDL for the ' + table_name + ' table:' + info)\n",
    "\n",
    "#merge the items\n",
    "tables_summary = '\\n\\n'.join(table_info)\n",
    "\n",
    "print(tables_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Prompt Template\n",
    "\n",
    "Create a simple template based on the original provided by the langchain repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_prompt = PromptTemplate(\n",
    "    input_variables=[],\n",
    "    template = f\"\"\"\n",
    "        You are a SQL Query Writer. Given an input question, first create a working {sql_dialect} SQL statement to find the answer to an input question and then return only the syntactically correct SQL statement.\n",
    "        \n",
    "        Use one or multiple of these tables:\n",
    "        {tables_summary} \n",
    "\n",
    "        Input question: \"{question}\"\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=[] output_parser=None partial_variables={} template='\\n        You are a SQL Query Writer. Given an input question, first create a working sqlite SQL statement to find the answer to an input question and then return only the syntactically correct SQL statement.\\n        \\n        Use one or multiple of these tables:\\n        DDL for the head table:\\nCREATE TABLE head (\\n\\t\"head_ID\" INTEGER, \\n\\tname TEXT, \\n\\tborn_state TEXT, \\n\\tage REAL, \\n\\tPRIMARY KEY (\"head_ID\")\\n)\\n\\n/*\\n3 rows from head table:\\nhead_ID\\tname\\tborn_state\\tage\\n1\\tTiger Woods\\tAlabama\\t67.0\\n2\\tSergio García\\tCalifornia\\t68.0\\n3\\tK. J. Choi\\tAlabama\\t69.0\\n*/\\n\\nDDL for the department table:\\nCREATE TABLE department (\\n\\t\"Department_ID\" INTEGER, \\n\\t\"Name\" TEXT, \\n\\t\"Creation\" TEXT, \\n\\t\"Ranking\" INTEGER, \\n\\t\"Budget_in_Billions\" REAL, \\n\\t\"Num_Employees\" REAL, \\n\\tPRIMARY KEY (\"Department_ID\")\\n)\\n\\n/*\\n3 rows from department table:\\nDepartment_ID\\tName\\tCreation\\tRanking\\tBudget_in_Billions\\tNum_Employees\\n1\\tState\\t1789\\t1\\t9.96\\t30266.0\\n2\\tTreasury\\t1789\\t2\\t11.1\\t115897.0\\n3\\tDefense\\t1947\\t3\\t439.3\\t3000000.0\\n*/\\n\\nDDL for the management table:\\nCREATE TABLE management (\\n\\t\"department_ID\" INTEGER, \\n\\t\"head_ID\" INTEGER, \\n\\ttemporary_acting TEXT, \\n\\tPRIMARY KEY (\"department_ID\", \"head_ID\"), \\n\\tFOREIGN KEY(\"head_ID\") REFERENCES head (\"head_ID\"), \\n\\tFOREIGN KEY(\"department_ID\") REFERENCES department (\"Department_ID\")\\n)\\n\\n/*\\n3 rows from management table:\\ndepartment_ID\\thead_ID\\ttemporary_acting\\n2\\t5\\tYes\\n15\\t4\\tYes\\n2\\t6\\tYes\\n*/ \\n\\n        Input question: \"How many heads of the departments are older than 56?\"\\n    ' template_format='f-string' validate_template=True\n"
     ]
    }
   ],
   "source": [
    "print(create_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup LLM\n",
    "I'll test the google flan-t5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get api key\n",
    "load_dotenv()\n",
    "hf_api_token = os.getenv('hf_token')\n",
    "\n",
    "#add path to HF repo\n",
    "repo_id = 'google/flan-t5-xxl'\n",
    "\n",
    "#establish llm model\n",
    "llm = HuggingFaceHub(repo_id=repo_id, huggingfacehub_api_token=hf_api_token, model_kwargs={\"temperature\": 0.1, \"max_length\": 512})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st Chain - Generate SQL Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=create_prompt, verbose=False)\n",
    "sql_query = chain.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT count(*) FROM head WHERE age > 56'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain for checking SQL Query\n",
    "\n",
    "This is directly from the langchain check query prompt. It looks for common mistakes in the initially written sql query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_prompt = PromptTemplate(\n",
    "    input_variables=[],\n",
    "    template = f\"\"\"{sql_query}\n",
    "\n",
    "    Double check the {sql_dialect} query above for common mistakes, including:\n",
    "    - Using NOT IN with NULL values\n",
    "    - Using UNION when UNION ALL should have been used\n",
    "    - Using BETWEEN for exclusive ranges\n",
    "    - Data type mismatch in predicates\n",
    "    - Properly quoting identifiers\n",
    "    - Using the correct number of arguments for functions\n",
    "    - Casting to the correct data type\n",
    "    - Using the proper columns for joins\n",
    "\n",
    "    If there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=validate_prompt, verbose=False)\n",
    "validated_query = chain.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT count(*) FROM head WHERE age > 56'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validated_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run and Debug the Query\n",
    "\n",
    "Run the query on the database, if it is succesful, send the results to an LLM to interpret them.\n",
    "If unsuccessful, ask and LLM to debug and write a new one based on the error message. And then try again, only exiting the loop once it works.\n",
    "\n",
    "The wonderful folks at langchain created a run_no_throw funciton that returns the successful results or the error message. Not a full big error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[(5,)]'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_output = db.run_no_throw(validated_query)\n",
    "\n",
    "sql_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create prompt for answering the question\n",
    "analyze_prompt = PromptTemplate(\n",
    "    input_variables=[],\n",
    "    template = f\"\"\"\n",
    "    You are an expert data analyst. Given an output of an SQL query, first look at the output and then determine the answer to a user question.\n",
    "    \n",
    "    SQL Output: \"{sql_output}\"\n",
    "    Question: \"{question}\"\n",
    "\n",
    "    Describe your answer with one sentence:\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test analyze chain\n",
    "chain = LLMChain(llm=llm, prompt=analyze_prompt, verbose=False)\n",
    "answer = chain.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The number of heads of the departments older than 56 is 5.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a query that should error to test off of\n",
    "bad_query = 'SELECT count(a) FROM head WHERE age > 56'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Error: (sqlite3.OperationalError) no such column: a\\n[SQL: SELECT count(a) FROM head WHERE age > 56]\\n(Background on this error at: https://sqlalche.me/e/20/e3q8)'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test what output looks like\n",
    "query_error = db.run_no_throw(bad_query)\n",
    "\n",
    "query_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create query that should return a null avlue\n",
    "empty_query = \"SELECT name FROM head WHERE head_id = '25'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[]'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_empty = db.run_no_throw(empty_query)\n",
    "\n",
    "test_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create prompt for debugging error\n",
    "debug_error_prompt = PromptTemplate(\n",
    "    input_variables=[],\n",
    "    template = f\"\"\"{bad_query}\n",
    "\n",
    "The query above produced the following error:\n",
    "\n",
    "{query_error}\n",
    "\n",
    "Rewrite the query with the error fixed:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create prompt for trying to fix an empty output\n",
    "debug_empty_prompt = PromptTemplate(\n",
    "    input_variables=[],\n",
    "    template = f\"\"\"{empty_query}\n",
    "\n",
    "The query above produced no result. Try rewriting the query so it will return results to this question \"{question}\":\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSELECT count(a) FROM head WHERE age > 56\n",
      "\n",
      "The query above produced the following error:\n",
      "\n",
      "Error: (sqlite3.OperationalError) no such column: a\n",
      "[SQL: SELECT count(a) FROM head WHERE age > 56]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "\n",
      "Rewrite the query with the error fixed:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#test debug\n",
    "chain = LLMChain(llm=llm, prompt=debug_error_prompt, verbose=True)\n",
    "debugged = chain.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT count(*) FROM head WHERE age > 56'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debugged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSELECT name FROM head WHERE head_id = '25'\n",
      "\n",
      "The query above produced no result. Try rewriting the query so it will return results to this question \"How many heads of the departments are older than 56?\":\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#test empty debug\n",
    "chain = LLMChain(llm=llm, prompt=debug_empty_prompt, verbose=True)\n",
    "emp_debugged = chain.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT count(*) FROM head WHERE age > 56'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_debugged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks to be working with the steps manually broken out. So now I'll work on creating functions to make this easier to repeat.\n",
    "\n",
    "## Create Functions\n",
    "\n",
    "### Selecting database, connecting to it, running all of the prompts, etc.\n",
    "\n",
    "I want to first build this out as a local application that has multiple entry point into the LLMs, and then work on building this out as a custom agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish unique chains\n",
    "create_chain = LLMChain(llm=llm, prompt=create_prompt, verbose=False)\n",
    "\n",
    "validate_chain = LLMChain(llm=llm, prompt=validate_prompt, verbose=False)\n",
    "\n",
    "analyze_chain = LLMChain(llm=llm, prompt=analyze_prompt, verbose=False)\n",
    "\n",
    "debug_error_chain = LLMChain(llm=llm, prompt=debug_error_prompt, verbose=False)\n",
    "\n",
    "debug_empty_chain = LLMChain(llm=llm, prompt=debug_empty_prompt, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_doc_search(question, vector_db=vectordb, k=3):\n",
    "    \"\"\"\n",
    "    Run similarity search through a vectordb query on the user input question and return the k most similar schema-table combinations in document form..\n",
    "    \"\"\"\n",
    "    similar_docs = vector_db.similarity_search(question, k)\n",
    "\n",
    "    return similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_schemas(documents):\n",
    "    \"\"\"\n",
    "    Take in a list of documents created from our similar_doc_search function.\n",
    "    Use the metadata.\n",
    "    And convert this into a set of unique schemas returned by that search.\n",
    "    \"\"\"\n",
    "    target_schemas = set(doc.metadata['schema'] for doc in documents)\n",
    "\n",
    "    return target_schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_db(db_path, target_schema):\n",
    "    \"\"\"\n",
    "    Take in the identified schema and connect to the sqlite database with that name\n",
    "    \"\"\"\n",
    "    db_filepath = db_path\n",
    "    db_filename = target_schema + '.sqlite'\n",
    "\n",
    "    #point to database\n",
    "    base_dir = os.path.dirname(os.path.abspath(db_filepath+db_filename)) #get the full path within the device\n",
    "    db_path = os.path.join(base_dir, db_filename) #combine with filename to get db_path\n",
    "    db = SQLDatabase.from_uri(\"sqlite:///\" + db_path) #connect via the lanchain method\n",
    "\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prioritize_tables(documents, target_schema, sql_database):\n",
    "    \"\"\"\n",
    "    Take in a list of similar_doc_search documents and prioritize tables from the same schema.\n",
    "    Sort all tables in the database based on the priority list.\n",
    "    \"\"\"\n",
    "    table_sorting = set(doc.metadata['table'] for doc in documents if doc.metadata['schema'] == target_schema)\n",
    "    table_names = sql_database.get_usable_table_names()\n",
    "    table_indices = {table: index for index, table in enumerate(table_sorting)}\n",
    "\n",
    "    priority_tables = sorted(table_names, key=lambda x: (table_indices.get(x, float('inf')), table_names.index(x)))\n",
    "\n",
    "    return priority_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_info(tables, database):\n",
    "    \"\"\"\n",
    "    Initialize an empty list, then loop through the list of tables in the database and save the DDL and 3 sample rows for each to a variable.\n",
    "    \"\"\"\n",
    "    table_info = []\n",
    "    for table in tables:\n",
    "        table_name = table\n",
    "        info = db.get_table_info(table_names=[table])\n",
    "        table_info.append('DDL for the ' + table_name + ' table:' + info)\n",
    "\n",
    "    #merge the items\n",
    "    tables_summary = '\\n\\n'.join(table_info)\n",
    "\n",
    "    return tables_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql_dialect(database):\n",
    "    \"\"\"\n",
    "    Return the sql dialaect from the database.\n",
    "    \"\"\"\n",
    "    sql_dialect = database.dialect\n",
    "\n",
    "    return sql_dialect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_create_sql(sql_dialect, table_info, question, lang_model):\n",
    "    create_prompt = PromptTemplate(\n",
    "    input_variables=[],\n",
    "    template = f\"\"\"\n",
    "        You are a SQL Query Writer. Given an input question, first create a working {sql_dialect} SQL statement to find the answer to an input question and then return only the syntactically correct SQL statement.\n",
    "        \n",
    "        Use one or multiple of these tables:\n",
    "        {table_info} \n",
    "\n",
    "        Input question: \"{question}\"\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    create_chain = LLMChain(llm=lang_model, prompt=create_prompt, verbose=False)\n",
    "\n",
    "    sql_query = create_chain.predict()\n",
    "\n",
    "    return sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_check_sql(sql_query, sql_dialect, lang_model):\n",
    "    validate_prompt = PromptTemplate(\n",
    "    input_variables=[],\n",
    "    template = f\"\"\"{sql_query}\n",
    "\n",
    "        Double check the {sql_dialect} query above for common mistakes, including:\n",
    "        - Using NOT IN with NULL values\n",
    "        - Using UNION when UNION ALL should have been used\n",
    "        - Using BETWEEN for exclusive ranges\n",
    "        - Data type mismatch in predicates\n",
    "        - Properly quoting identifiers\n",
    "        - Using the correct number of arguments for functions\n",
    "        - Casting to the correct data type\n",
    "        - Using the proper columns for joins\n",
    "\n",
    "        If there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\"\"\"\n",
    "    )\n",
    "\n",
    "    validate_chain = LLMChain(llm=lang_model, prompt=validate_prompt, verbose=False)\n",
    "\n",
    "    checked_sql = validate_chain.predict()\n",
    "\n",
    "    return checked_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sql(database, sql_query):\n",
    "    query_result = database.run_no_throw(sql_query)\n",
    "\n",
    "    return query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_debug_error(sql_query, error_message, lang_model):\n",
    "    \"\"\"\n",
    "    To be executed if the SQL query returns an error message\n",
    "    Will provide the error message to the LLM and ask it to debug, returning a new query\n",
    "    \"\"\"\n",
    "    #setup the debugging prompt\n",
    "    debug_error_prompt = PromptTemplate(\n",
    "        input_variables=[],\n",
    "        template = f\"\"\"{sql_query}\n",
    "\n",
    "    The query above produced the following error:\n",
    "\n",
    "    {error_message}\n",
    "\n",
    "    Rewrite the query with the error fixed:\"\"\"\n",
    "    )\n",
    "\n",
    "    debug_error_chain = LLMChain(llm=lang_model, prompt=debug_error_prompt, verbose=False)\n",
    "\n",
    "    debugged_query = debug_error_chain.predict()\n",
    "\n",
    "    return debugged_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_debug_empty(sql_query, question, lang_model):\n",
    "    \"\"\"\n",
    "    To be executed if the SQL query returns an empty string.\n",
    "    Will provide a prompt to the LLM asking it to re-review the original question and data and write a new query\n",
    "    \"\"\"\n",
    "    debug_empty_prompt = PromptTemplate(\n",
    "        input_variables=[],\n",
    "        template = f\"\"\"{sql_query}\n",
    "\n",
    "        The query above produced no result. Try rewriting the query so it will return results to this question \"{question}\":\"\"\"\n",
    "        )\n",
    "    \n",
    "    debug_empty_chain = LLMChain(llm=lang_model, prompt=debug_empty_prompt, verbose=False)\n",
    "\n",
    "    debugged_query = debug_empty_chain.predict()\n",
    "\n",
    "    return debugged_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_analyze(sql_query, query_result, question, lang_model):\n",
    "    \"\"\"\n",
    "    To be executed if the run SQL query returns a valid results.\n",
    "    Will provide the full output of the original question, final sql query, and answer.\n",
    "    \"\"\"\n",
    "    analyze_prompt = PromptTemplate(\n",
    "        input_variables=[],\n",
    "        template = f\"\"\"{query_result}\n",
    "\n",
    "        You are an expert data analyst. First look at the results of the above SQL output then identify the answer to this question:\n",
    "        Question: \"{question}\"\n",
    "\n",
    "        Then the answer in one sentence:\n",
    "        \"\"\"\n",
    "        )\n",
    "    \n",
    "    analyze_chain = LLMChain(llm=lang_model, prompt=analyze_prompt, verbose=False)\n",
    "    \n",
    "    llm_answer = analyze_chain.predict()\n",
    "    \n",
    "    output = f\"\"\"\n",
    "            Input question: {question}\n",
    "            SQL Query: {sql_query}\n",
    "            Answer: {llm_answer}\"\"\"\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_and_run(max_attempts=3, sql_query=validated_query):\n",
    "    \"\"\"\n",
    "    Execute the validated SQL query and try `max_attempts` times.\n",
    "    If successful, return the query result.\n",
    "    If not, raise an exception or return an appropriate error message.\n",
    "    \"\"\"\n",
    "    attempt = 1\n",
    "    while attempt <= max_attempts:\n",
    "        query_result = db.run_no_throw(sql_query)\n",
    "\n",
    "        if query_result[:5] == 'Error':\n",
    "            if attempt == max_attempts:\n",
    "                output = f\"Unable to execute the SQL query after {max_attempts} attempts.\"\n",
    "                break\n",
    "\n",
    "            sql_query = debug_error_chain.predict()\n",
    "            attempt += 1\n",
    "            time.sleep(1)  # Add a delay of 1 second between attempts\n",
    "\n",
    "\n",
    "        elif query_result == '[]':\n",
    "            if attempt == max_attempts:\n",
    "                output = \"Query returned no results after multiple attempts.\"\n",
    "                break\n",
    "\n",
    "            sql_query = debug_empty_chain.predict()\n",
    "            attempt +=1\n",
    "            time.sleep(1)  # Add a delay of 1 second between attempts\n",
    "\n",
    "        else:\n",
    "            answer = analyze_chain.predict()\n",
    "            output = f\"\"\"\n",
    "            Input question: {question}\n",
    "            SQL Query: {sql_query}\n",
    "            Answer: {query_result}\"\"\"\n",
    "            break\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT count(*) FROM head WHERE age > 56'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validated_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            Input question: How many heads of the departments are older than 56?\n",
      "            SQL Query: SELECT count(*) FROM head WHERE age > 56\n",
      "            Answer: [(5,)]\n"
     ]
    }
   ],
   "source": [
    "output = debug_and_run()\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "This is working for simple quesiton, but will have a fun roadmap of improvements to work on. But I'm happy with it as a proof of concept so I'll work on building this into .py files that can run through the terminal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text2sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
