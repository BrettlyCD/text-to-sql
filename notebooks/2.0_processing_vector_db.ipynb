{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Schema Data to Vector Database\n",
    "\n",
    "My initial thought was to build a model that checks for similarity between the prompt and the schema information. But in doing research it sounds like this could be simplified and expedited using a vector database through langchain. We could then query the tables (with metadata) based on the question and return the documents that are most closely related. With this, we'll try to all be bundled into langchain. woohoo!\n",
    "\n",
    "Big shoutout to this great blogpost that provided some of the framework: https://canvasapp.com/blog/text-to-sql-in-production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from sqlalchemy import exc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json(path):\n",
    "    \"\"\"Return json file from specified filepath\"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        json_file = json.load(f)\n",
    "    \n",
    "    return json_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_chroma_documents(json_path):\n",
    "    \"\"\"Take json file and work through it to prepare for load to Chroma.\n",
    "    Instead of list comprehension, establis the blank list and loop through the json.\n",
    "    Then saves to the list using the langchain docstore.document -> Document modeul\n",
    "\n",
    "    This works specifically with the content and metadata we want for this project\"\"\"\n",
    "    docs = []\n",
    "    for item in get_json(json_path):\n",
    "        doc = Document(\n",
    "            page_content=f\"Schema Table: {item['schema_split'] + ' ' + item['table_split']}\",\n",
    "            metadata={\n",
    "                'schema': item['schema'],\n",
    "                'table': item['table'],\n",
    "                'columns': json.dumps([col['c_name'] for col in item['columns']])\n",
    "            }\n",
    "        )\n",
    "        docs.append(doc)\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Schema Table: academic author', metadata={'schema': 'academic', 'table': 'author', 'columns': '[\"aid\", \"homepage\", \"name\", \"oid\"]'}),\n",
       " Document(page_content='Schema Table: academic cite', metadata={'schema': 'academic', 'table': 'cite', 'columns': '[\"cited\", \"citing\"]'}),\n",
       " Document(page_content='Schema Table: academic conference', metadata={'schema': 'academic', 'table': 'conference', 'columns': '[\"cid\", \"homepage\", \"name\"]'})]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_info = prep_chroma_documents('../data/interim/schema_info.json')\n",
    "\n",
    "table_info[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish Vector Database\n",
    "\n",
    "There are a few options for databases, but I'll go with Chroma because it is open source, makes local device use \"easy\", and has built-in connections with langchain.\n",
    "\n",
    "A key component in running apps using langchain is the ability store and work with embeddings, which is how AI models natively represent data of all kinds. Langchain will provide the application framework and Chroma will provide the vector store.\n",
    "\n",
    "Within that we can also do some information retrieval from the database, finding the most relevant tables based on the user question. This will allow us to engineer a better prompt to feed to our gpt chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup embeddings using HuggingFace\n",
    "embeddings  = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup directory to store database on disk\n",
    "persist_dir = '../data/processed/chromadb/schema-table-split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(documents=table_info, embedding=embeddings, persist_directory=persist_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Persist DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist() #think I need to call this mainly because I'm in an ipynb.\n",
    "vectordb=None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Vector Database Query\n",
    "\n",
    "I'm going to start very simple and follow this first prompt through to the end. So for now, I'll only take the top result and roll with it. In the future we'll need to build out some contingency that can test multiple schemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from disk\n",
    "vectordb = Chroma(persist_directory=persist_dir, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How many heads of the departments are older than 56?\" #one of the prompts from the training data\n",
    "\n",
    "docs = vectordb.similarity_search(query, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Likely Schema and Table:\n",
      "\n",
      "department_management - head\n"
     ]
    }
   ],
   "source": [
    "print('Most Likely Schema and Table:\\n')\n",
    "i=0\n",
    "for doc in docs:\n",
    "    print(docs[i].metadata['schema'] + ' - ' + docs[i].metadata['table'])\n",
    "    i+=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations and Next Steps\n",
    "\n",
    "This change appears to have worked on the first test example. In the first run with no processing and searching on a document that contained table title and metadata it gave me the wrong answer. But doing some preprocessing, splitting out any names that contained '_' into two words and restructuring the document to include 'schema table' looks to have helped a bit.\n",
    "\n",
    "I'll continue on with next steps, push this to main, and come back when I'm ready to complicate things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tune Documents\n",
    "\n",
    "The last method only gave around 50% accuracy on identifying the right database. I wonder if there is a way to train a model, but I also want to try providing the database more detailed metadata- Specifically some sample data from the tables.\n",
    "\n",
    "### Establish New Document Structure\n",
    "\n",
    "Start by prepping the table info - I'll try using the full langchain get_table_info method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import langchain's SQLDatabase tools to get table information\n",
    "from langchain import SQLDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = '../data/processed/db/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_db(db_path, target_schema):\n",
    "    \"\"\"\n",
    "    Take in the identified schema and connect to the sqlite database with that name\n",
    "    \"\"\"\n",
    "    db_filepath = db_path\n",
    "    db_filename = target_schema + '.sqlite'\n",
    "\n",
    "    #point to database\n",
    "    base_dir = os.path.dirname(os.path.abspath(db_filepath+db_filename)) #get the full path within the device\n",
    "    db_path = os.path.join(base_dir, db_filename) #combine with filename to get db_path\n",
    "    db = SQLDatabase.from_uri(\"sqlite:///\" + db_path) #connect via the lanchain method\n",
    "\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define new document builder\n",
    "def prep_chroma_documents_v2(json_path):\n",
    "    \"\"\"Take json file and work through it to prepare for load to Chroma.\n",
    "    Instead of list comprehension, establis the blank list and loop through the json.\n",
    "    Then saves to the list using the langchain docstore.document -> Document module.\n",
    "\n",
    "    This version - adding the table info using the langchain SQLDatabase SQLAlchemy wrapper to get table info to add to metadata.\n",
    "    Would like to not reconnect to the database each time, but instead connect to each schema once and then loop through the tables. But I think this will be easier for now, even if it's less efficient.\n",
    "\n",
    "    This works specifically with the content and metadata we want for this project\"\"\"\n",
    "    docs = []\n",
    "    for item in get_json(json_path):\n",
    "        #connect to database\n",
    "        db = connect_db(db_path=db_path, target_schema=item['schema'])\n",
    "\n",
    "        #create variables\n",
    "        schema = item['schema']\n",
    "        table = item['table']\n",
    "        columns = json.dumps([col['c_name'] for col in item['columns']])\n",
    "        try:\n",
    "            table_info = db.get_table_info_no_throw(table_names=[table]) #put try-except here becasue there are some issues in the source sqlite database. I want to call this out, but continue.\n",
    "        except exc.SQLAlchemyError as e:\n",
    "            table_info = \"\"\n",
    "            print(schema + \"-\" + table + \": \" + str(e))\n",
    "            continue\n",
    "        except TypeError as te:\n",
    "            print(schema + \"-\" + table + \": \" + str(te))       \n",
    "            continue   \n",
    "\n",
    "        #create document\n",
    "        doc = Document(\n",
    "            page_content=\n",
    "                f\"\"\"Schema: {schema}\n",
    "                Table: {table}\n",
    "                Columns: {columns}\n",
    "                DDL:\n",
    "                    {table_info}\n",
    "                \"\"\",\n",
    "            metadata={\n",
    "                'schema': schema,\n",
    "                'table': table,\n",
    "                'columns': columns,\n",
    "                'table_info': table_info\n",
    "            }\n",
    "        )\n",
    "        docs.append(doc)\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brettly/opt/anaconda3/envs/text2sql/lib/python3.11/site-packages/langchain/sql_database.py:111: SAWarning: Could not instantiate type <class 'sqlalchemy.sql.sqltypes.INTEGER'> with reflected arguments ['11']; using no arguments.\n",
      "  self._metadata.reflect(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseball_1-all_star: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "baseball_1-appearances: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "baseball_1-batting: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "baseball_1-batting_postseason: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "baseball_1-college: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "baseball_1-fielding: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "baseball_1-fielding_outfield: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "baseball_1-fielding_postseason: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "baseball_1-hall_of_fame: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "baseball_1-home_game: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "baseball_1-manager: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "baseball_1-manager_award: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "baseball_1-manager_award_vote: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "baseball_1-manager_half: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "baseball_1-park: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "baseball_1-pitching: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "baseball_1-pitching_postseason: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "baseball_1-player: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "baseball_1-player_award: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "baseball_1-player_award_vote: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "baseball_1-player_college: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "baseball_1-postseason: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "baseball_1-salary: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "baseball_1-team: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "baseball_1-team_franchise: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "baseball_1-team_half: Could not initialize target column for ForeignKey 'player.team_id' on table 'fielding_postseason': table 'player' has no column named 'team_id'\n",
      "imdb-actor: Could not initialize target column for ForeignKey 'keyword.kid' on table 'tags': table 'keyword' has no column named 'kid'\n",
      "imdb-cast: Could not initialize target column for ForeignKey 'keyword.kid' on table 'tags': table 'keyword' has no column named 'kid'\n",
      "imdb-classification: Could not initialize target column for ForeignKey 'keyword.kid' on table 'tags': table 'keyword' has no column named 'kid'\n",
      "imdb-company: Could not initialize target column for ForeignKey 'keyword.kid' on table 'tags': table 'keyword' has no column named 'kid'\n",
      "imdb-copyright: Could not initialize target column for ForeignKey 'keyword.kid' on table 'tags': table 'keyword' has no column named 'kid'\n",
      "imdb-directed_by: Could not initialize target column for ForeignKey 'keyword.kid' on table 'tags': table 'keyword' has no column named 'kid'\n",
      "imdb-director: Could not initialize target column for ForeignKey 'keyword.kid' on table 'tags': table 'keyword' has no column named 'kid'\n",
      "imdb-genre: Could not initialize target column for ForeignKey 'keyword.kid' on table 'tags': table 'keyword' has no column named 'kid'\n",
      "imdb-keyword: Could not initialize target column for ForeignKey 'keyword.kid' on table 'tags': table 'keyword' has no column named 'kid'\n",
      "imdb-made_by: Could not initialize target column for ForeignKey 'keyword.kid' on table 'tags': table 'keyword' has no column named 'kid'\n",
      "imdb-movie: Could not initialize target column for ForeignKey 'keyword.kid' on table 'tags': table 'keyword' has no column named 'kid'\n",
      "imdb-producer: Could not initialize target column for ForeignKey 'keyword.kid' on table 'tags': table 'keyword' has no column named 'kid'\n",
      "imdb-tags: Could not initialize target column for ForeignKey 'keyword.kid' on table 'tags': table 'keyword' has no column named 'kid'\n",
      "imdb-tv_series: Could not initialize target column for ForeignKey 'keyword.kid' on table 'tags': table 'keyword' has no column named 'kid'\n",
      "imdb-writer: Could not initialize target column for ForeignKey 'keyword.kid' on table 'tags': table 'keyword' has no column named 'kid'\n",
      "imdb-written_by: Could not initialize target column for ForeignKey 'keyword.kid' on table 'tags': table 'keyword' has no column named 'kid'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brettly/opt/anaconda3/envs/text2sql/lib/python3.11/site-packages/langchain/sql_database.py:111: SAWarning: WARNING: SQL-parsed foreign key constraint '('Cust_ID', 'customer', 'Cust_ID')' could not be located in PRAGMA foreign_keys for table loan\n",
      "  self._metadata.reflect(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_1-bank: Could not initialize target column for ForeignKey 'customer.Cust_ID' on table 'loan': table 'customer' has no column named 'Cust_ID'\n",
      "loan_1-customer: Could not initialize target column for ForeignKey 'customer.Cust_ID' on table 'loan': table 'customer' has no column named 'Cust_ID'\n",
      "loan_1-loan: Could not initialize target column for ForeignKey 'customer.Cust_ID' on table 'loan': table 'customer' has no column named 'Cust_ID'\n",
      "restaurants-GEOGRAPHIC: Could not initialize target column for ForeignKey 'RESTAURANT.RESTAURANT_ID' on table 'LOCATION': table 'RESTAURANT' has no column named 'RESTAURANT_ID'\n",
      "restaurants-LOCATION: Could not initialize target column for ForeignKey 'RESTAURANT.RESTAURANT_ID' on table 'LOCATION': table 'RESTAURANT' has no column named 'RESTAURANT_ID'\n",
      "restaurants-RESTAURANT: Could not initialize target column for ForeignKey 'RESTAURANT.RESTAURANT_ID' on table 'LOCATION': table 'RESTAURANT' has no column named 'RESTAURANT_ID'\n",
      "sakila_1-film: (in table 'film', column 'rating'): Can't generate DDL for NullType(); did you forget to specify a type on this Column?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brettly/opt/anaconda3/envs/text2sql/lib/python3.11/site-packages/langchain/sql_database.py:111: SAWarning: WARNING: SQL-parsed foreign key constraint '('store_id', 'store', 'store_id')' could not be located in PRAGMA foreign_keys for table staff\n",
      "  self._metadata.reflect(\n",
      "/Users/brettly/opt/anaconda3/envs/text2sql/lib/python3.11/site-packages/langchain/sql_database.py:111: SAWarning: WARNING: SQL-parsed foreign key constraint '('Event_ID', 'Events', 'Event_ID')' could not be located in PRAGMA foreign_keys for table Assets_in_Events\n",
      "  self._metadata.reflect(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store_product-district: Could not initialize target column for ForeignKey 'product.Product_ID' on table 'store_product': table 'product' has no column named 'Product_ID'\n",
      "store_product-product: Could not initialize target column for ForeignKey 'product.Product_ID' on table 'store_product': table 'product' has no column named 'Product_ID'\n",
      "store_product-store: Could not initialize target column for ForeignKey 'product.Product_ID' on table 'store_product': table 'product' has no column named 'Product_ID'\n",
      "store_product-store_district: Could not initialize target column for ForeignKey 'product.Product_ID' on table 'store_product': table 'product' has no column named 'Product_ID'\n",
      "store_product-store_product: Could not initialize target column for ForeignKey 'product.Product_ID' on table 'store_product': table 'product' has no column named 'Product_ID'\n",
      "wta_1-matches: fromisoformat: argument must be str\n",
      "wta_1-players: fromisoformat: argument must be str\n",
      "wta_1-rankings: fromisoformat: argument must be str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brettly/opt/anaconda3/envs/text2sql/lib/python3.11/site-packages/langchain/sql_database.py:111: SAWarning: Could not instantiate type <class 'sqlalchemy.sql.sqltypes.BIGINT'> with reflected arguments ['20']; using no arguments.\n",
      "  self._metadata.reflect(\n"
     ]
    }
   ],
   "source": [
    "table_docs = prep_chroma_documents_v2('../data/interim/schema_info.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were errors on 3 or 4 of the source tables, but this looks to have worked. I'll now get this stored in a database.\n",
    "\n",
    "### Setup New Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup directory to store database on disk\n",
    "persist_dir_new = '../data/processed/chromadb/schema-metadata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb_new = Chroma.from_documents(documents=table_docs, embedding=embeddings, persist_directory=persist_dir_new)\n",
    "\n",
    "vectordb_new.persist() #think I need to call this mainly because I'm in an ipynb.\n",
    "vectordb_new=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test New DB with one of the questions that errored out on the original method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Schema: hr_1\\n                Table: departments\\n                Columns: [\"DEPARTMENT_ID\", \"DEPARTMENT_NAME\", \"MANAGER_ID\", \"LOCATION_ID\"]\\n                DDL:\\n                    \\nCREATE TABLE departments (\\n\\t\"DEPARTMENT_ID\" DECIMAL(4, 0) DEFAULT \\'0\\' NOT NULL, \\n\\t\"DEPARTMENT_NAME\" VARCHAR(30) NOT NULL, \\n\\t\"MANAGER_ID\" DECIMAL(6, 0) DEFAULT NULL, \\n\\t\"LOCATION_ID\" DECIMAL(4, 0) DEFAULT NULL, \\n\\tPRIMARY KEY (\"DEPARTMENT_ID\")\\n)\\n\\n/*\\n3 rows from departments table:\\nDEPARTMENT_ID\\tDEPARTMENT_NAME\\tMANAGER_ID\\tLOCATION_ID\\n10\\tAdministration\\t200\\t1700\\n20\\tMarketing\\t201\\t1800\\n30\\tPurchasing\\t114\\t1700\\n*/\\n                ', metadata={'schema': 'hr_1', 'table': 'departments', 'columns': '[\"DEPARTMENT_ID\", \"DEPARTMENT_NAME\", \"MANAGER_ID\", \"LOCATION_ID\"]', 'table_info': '\\nCREATE TABLE departments (\\n\\t\"DEPARTMENT_ID\" DECIMAL(4, 0) DEFAULT \\'0\\' NOT NULL, \\n\\t\"DEPARTMENT_NAME\" VARCHAR(30) NOT NULL, \\n\\t\"MANAGER_ID\" DECIMAL(6, 0) DEFAULT NULL, \\n\\t\"LOCATION_ID\" DECIMAL(4, 0) DEFAULT NULL, \\n\\tPRIMARY KEY (\"DEPARTMENT_ID\")\\n)\\n\\n/*\\n3 rows from departments table:\\nDEPARTMENT_ID\\tDEPARTMENT_NAME\\tMANAGER_ID\\tLOCATION_ID\\n10\\tAdministration\\t200\\t1700\\n20\\tMarketing\\t201\\t1800\\n30\\tPurchasing\\t114\\t1700\\n*/'}),\n",
       " Document(page_content='Schema: department_management\\n                Table: department\\n                Columns: [\"Department_ID\", \"Name\", \"Creation\", \"Ranking\", \"Budget_in_Billions\", \"Num_Employees\"]\\n                DDL:\\n                    \\nCREATE TABLE department (\\n\\t\"Department_ID\" INTEGER, \\n\\t\"Name\" TEXT, \\n\\t\"Creation\" TEXT, \\n\\t\"Ranking\" INTEGER, \\n\\t\"Budget_in_Billions\" REAL, \\n\\t\"Num_Employees\" REAL, \\n\\tPRIMARY KEY (\"Department_ID\")\\n)\\n\\n/*\\n3 rows from department table:\\nDepartment_ID\\tName\\tCreation\\tRanking\\tBudget_in_Billions\\tNum_Employees\\n1\\tState\\t1789\\t1\\t9.96\\t30266.0\\n2\\tTreasury\\t1789\\t2\\t11.1\\t115897.0\\n3\\tDefense\\t1947\\t3\\t439.3\\t3000000.0\\n*/\\n                ', metadata={'schema': 'department_management', 'table': 'department', 'columns': '[\"Department_ID\", \"Name\", \"Creation\", \"Ranking\", \"Budget_in_Billions\", \"Num_Employees\"]', 'table_info': '\\nCREATE TABLE department (\\n\\t\"Department_ID\" INTEGER, \\n\\t\"Name\" TEXT, \\n\\t\"Creation\" TEXT, \\n\\t\"Ranking\" INTEGER, \\n\\t\"Budget_in_Billions\" REAL, \\n\\t\"Num_Employees\" REAL, \\n\\tPRIMARY KEY (\"Department_ID\")\\n)\\n\\n/*\\n3 rows from department table:\\nDepartment_ID\\tName\\tCreation\\tRanking\\tBudget_in_Billions\\tNum_Employees\\n1\\tState\\t1789\\t1\\t9.96\\t30266.0\\n2\\tTreasury\\t1789\\t2\\t11.1\\t115897.0\\n3\\tDefense\\t1947\\t3\\t439.3\\t3000000.0\\n*/'}),\n",
       " Document(page_content='Schema: hr_1\\n                Table: jobs\\n                Columns: [\"JOB_ID\", \"JOB_TITLE\", \"MIN_SALARY\", \"MAX_SALARY\"]\\n                DDL:\\n                    \\nCREATE TABLE jobs (\\n\\t\"JOB_ID\" VARCHAR(10) DEFAULT \\'\\' NOT NULL, \\n\\t\"JOB_TITLE\" VARCHAR(35) NOT NULL, \\n\\t\"MIN_SALARY\" DECIMAL(6, 0) DEFAULT NULL, \\n\\t\"MAX_SALARY\" DECIMAL(6, 0) DEFAULT NULL, \\n\\tPRIMARY KEY (\"JOB_ID\")\\n)\\n\\n/*\\n3 rows from jobs table:\\nJOB_ID\\tJOB_TITLE\\tMIN_SALARY\\tMAX_SALARY\\nAD_PRES\\tPresident\\t20000\\t40000\\nAD_VP\\tAdministration Vice President\\t15000\\t30000\\nAD_ASST\\tAdministration Assistant\\t3000\\t6000\\n*/\\n                ', metadata={'schema': 'hr_1', 'table': 'jobs', 'columns': '[\"JOB_ID\", \"JOB_TITLE\", \"MIN_SALARY\", \"MAX_SALARY\"]', 'table_info': '\\nCREATE TABLE jobs (\\n\\t\"JOB_ID\" VARCHAR(10) DEFAULT \\'\\' NOT NULL, \\n\\t\"JOB_TITLE\" VARCHAR(35) NOT NULL, \\n\\t\"MIN_SALARY\" DECIMAL(6, 0) DEFAULT NULL, \\n\\t\"MAX_SALARY\" DECIMAL(6, 0) DEFAULT NULL, \\n\\tPRIMARY KEY (\"JOB_ID\")\\n)\\n\\n/*\\n3 rows from jobs table:\\nJOB_ID\\tJOB_TITLE\\tMIN_SALARY\\tMAX_SALARY\\nAD_PRES\\tPresident\\t20000\\t40000\\nAD_VP\\tAdministration Vice President\\t15000\\t30000\\nAD_ASST\\tAdministration Assistant\\t3000\\t6000\\n*/'})]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load from disk\n",
    "vectordb_new = Chroma(persist_directory=persist_dir_new, embedding_function=embeddings)\n",
    "\n",
    "test = \"What is the average number of employees of the departments whose rank is between 10 and 15?\" #one of the prompts from the training data\n",
    "\n",
    "test_docs = vectordb_new.similarity_search(test, k=3)\n",
    "\n",
    "test_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This didn't put it in the 1st spot, but it is in the top three. I'll switch over to our other notebook and run the full result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text2sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
