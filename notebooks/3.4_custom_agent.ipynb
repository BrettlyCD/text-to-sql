{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Agent\n",
    "\n",
    "I had limited success with the built-in functions, so I'll test a custom flow, really a combination of tweaked langchain functions.\n",
    "\n",
    "I think part of this could be more specialized schema and table extraction, but for now I think I'll stick with my single schema example and try to expand later.\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain import HuggingFaceHub, SQLDatabase\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup query\n",
    "We'll use this to input into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How many rows in the 'head' table in the 'department_management' schema?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Target Tables from Vectordb\n",
    "\n",
    "Load in the top 3 results and save just the unique schemas to a set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup embeddings using HuggingFace and the directory location\n",
    "embeddings  = HuggingFaceEmbeddings()\n",
    "persist_dir = '../data/processed/chromadb/schema-table-split'\n",
    "\n",
    "# load from disk\n",
    "vectordb = Chroma(persist_directory=persist_dir, embedding_function=embeddings)\n",
    "\n",
    "#run similarity search\n",
    "top_results = vectordb.similarity_search(question, k=3) #just return the top for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'department_management'"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_results[0].metadata['schema']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Target Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'department_management'}\n"
     ]
    }
   ],
   "source": [
    "target_schemas = set()\n",
    "for doc in top_results:\n",
    "    schema = doc.metadata['schema']\n",
    "    target_schemas.add(schema)\n",
    "\n",
    "print(target_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'department_management'"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(target_schemas)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool - Query for Schema Information\n",
    "Use the langchain SQLDatabase class to get all the information about the schema. I think I also want to use the most likely columns returned to sort and prioritize how the tables are fed into the llm.\n",
    "\n",
    "I could load in the sql_query tools from langchain.tools, but I want to tweek things a little bit, especially in the order. I could come back to this later if it does simplify things and my way doesn't make the outcome any better.\n",
    "\n",
    "#### Point to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_filepath = '../data/processed/db/'\n",
    "db_filename = list(target_schemas)[0] + '.sqlite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "#point to database\n",
    "base_dir = os.path.dirname(os.path.abspath(db_filepath+db_filename)) #get the full path within the device\n",
    "db_path = os.path.join(base_dir, db_filename) #combine with filename to get db_path\n",
    "db = SQLDatabase.from_uri(\"sqlite:///\" + db_path) #connect via the lanchain method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set table sorting and then pull tables names using langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['management', 'head', 'department']\n"
     ]
    }
   ],
   "source": [
    "#pull the table names from the vector query so we can have them in order of similarity to the question.\n",
    "table_sorting = set()\n",
    "for doc in top_results:\n",
    "    schema = doc.metadata['schema']\n",
    "    if schema == 'department_management':\n",
    "        table_name = doc.metadata['table']\n",
    "        table_sorting.add(table_name)\n",
    "table_sorting = list(table_sorting)\n",
    "print(table_sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['management', 'head', 'department']"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get tables names\n",
    "table_names = db.get_usable_table_names()\n",
    "\n",
    "#sort by the results of our vector query to load the most likely table in first. Not sure if this will make a difference, but can't imagine it would hurt.\n",
    "priority_tables = sorted(table_names, key=lambda x: (table_sorting.index(x) if x in table_sorting else float('inf'), table_names.index(x)))\n",
    "\n",
    "priority_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get SQL Dialect\n",
    "\n",
    "Using the langchain class again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sqlite'"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_dialect = db.dialect\n",
    "\n",
    "sql_dialect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get table info\n",
    "\n",
    "You can do this for all tables in the database automatically with the function, but I want to continue trying to order these by likelihood of being related to the question. So I'll do this in a loop.\n",
    "\n",
    "This gives the full create statement and 3 sample rows, which I think will be a great start. And really gets us to where the Chain does for adding to the prompt template. I'll also combine this with the table name at the start of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DDL for the management table:\\nCREATE TABLE management (\\n\\t\"department_ID\" INTEGER, \\n\\t\"head_ID\" INTEGER, \\n\\ttemporary_acting TEXT, \\n\\tPRIMARY KEY (\"department_ID\", \"head_ID\"), \\n\\tFOREIGN KEY(\"head_ID\") REFERENCES head (\"head_ID\"), \\n\\tFOREIGN KEY(\"department_ID\") REFERENCES department (\"Department_ID\")\\n)\\n\\n/*\\n3 rows from management table:\\ndepartment_ID\\thead_ID\\ttemporary_acting\\n2\\t5\\tYes\\n15\\t4\\tYes\\n2\\t6\\tYes\\n*/\\n\\nDDL for the head table:\\nCREATE TABLE head (\\n\\t\"head_ID\" INTEGER, \\n\\tname TEXT, \\n\\tborn_state TEXT, \\n\\tage REAL, \\n\\tPRIMARY KEY (\"head_ID\")\\n)\\n\\n/*\\n3 rows from head table:\\nhead_ID\\tname\\tborn_state\\tage\\n1\\tTiger Woods\\tAlabama\\t67.0\\n2\\tSergio Garc√≠a\\tCalifornia\\t68.0\\n3\\tK. J. Choi\\tAlabama\\t69.0\\n*/\\n\\nDDL for the department table:\\nCREATE TABLE department (\\n\\t\"Department_ID\" INTEGER, \\n\\t\"Name\" TEXT, \\n\\t\"Creation\" TEXT, \\n\\t\"Ranking\" INTEGER, \\n\\t\"Budget_in_Billions\" REAL, \\n\\t\"Num_Employees\" REAL, \\n\\tPRIMARY KEY (\"Department_ID\")\\n)\\n\\n/*\\n3 rows from department table:\\nDepartment_ID\\tName\\tCreation\\tRanking\\tBudget_in_Billions\\tNum_Employees\\n1\\tState\\t1789\\t1\\t9.96\\t30266.0\\n2\\tTreasury\\t1789\\t2\\t11.1\\t115897.0\\n3\\tDefense\\t1947\\t3\\t439.3\\t3000000.0\\n*/'"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_info = []\n",
    "for table in priority_tables:\n",
    "    table_name = table\n",
    "    info = db.get_table_info(table_names=[table])\n",
    "    table_info.append('DDL for the ' + table_name + ' table:' + info)\n",
    "\n",
    "#merge the items\n",
    "tables_summary = '\\n\\n'.join(table_info)\n",
    "\n",
    "tables_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_prompt = PromptTemplate(\n",
    "    input_variables=[],\n",
    "    template = f\"\"\"\n",
    "        You are a SQL Query Writer. Given an input question, first create a working {sql_dialect} SQL statement to find the answer to an input question and then return only the syntactically correct SQL statement.\n",
    "        \n",
    "        Use one or multiple of these tables:\n",
    "        {tables_summary} \n",
    "\n",
    "        Input question: \"{question}\"\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup LLM\n",
    "I'll test the google flan-t5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get api key\n",
    "load_dotenv()\n",
    "hf_api_token = os.getenv('hf_token')\n",
    "\n",
    "#add path to HF repo\n",
    "repo_id = 'google/flan-t5-xxl'\n",
    "\n",
    "#establish llm model\n",
    "llm = HuggingFaceHub(repo_id=repo_id, huggingfacehub_api_token=hf_api_token, model_kwargs={\"temperature\": 0.1, \"max_length\": 256})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st Chain - Generate SQL Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=create_prompt, verbose=False)\n",
    "sql_query = chain.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT Count ( * ) FROM head'"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain for checking SQL Query\n",
    "\n",
    "This is directly from the langchain check query prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_prompt = PromptTemplate(\n",
    "    input_variables=[],\n",
    "    template = f\"\"\"{sql_query}\n",
    "\n",
    "    Double check the {sql_dialect} query above for common mistakes, including:\n",
    "    - Using NOT IN with NULL values\n",
    "    - Using UNION when UNION ALL should have been used\n",
    "    - Using BETWEEN for exclusive ranges\n",
    "    - Data type mismatch in predicates\n",
    "    - Properly quoting identifiers\n",
    "    - Using the correct number of arguments for functions\n",
    "    - Casting to the correct data type\n",
    "    - Using the proper columns for joins\n",
    "\n",
    "    If there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=validate_prompt, verbose=False)\n",
    "validated_query = chain.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT count(*) FROM head'"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validated_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions - Identify & Connect to DB, Get & Prioritize Tables, Create & Validate Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create unique chains\n",
    "create_chain = LLMChain(llm=llm, prompt=create_prompt, verbose=False)\n",
    "\n",
    "validate_chain = LLMChain(llm=llm, prompt=validate_prompt, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sql(question):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run and Debug the Query\n",
    "\n",
    "Run the query on the database, if it is succesful, send the results to an LLM to interpret them.\n",
    "If unsuccessful, ask and LLM to debug and write a new one based on the error message. And then try again, only exiting the loop once it works.\n",
    "\n",
    "The wonderful folks at langchain created a run_no_throw funciton that returns the successful results or the error message. Not a full big error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[(10,)]'"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_output = db.run_no_throw(validated_query)\n",
    "\n",
    "sql_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create prompt for answering the question\n",
    "analyze_prompt = PromptTemplate(\n",
    "    input_variables=[],\n",
    "    template = f\"\"\"{sql_output}\n",
    "\n",
    "    You are an expert data analyst. First look at the results of the above SQL output then identify the answer to this question:\n",
    "    Question: \"{question}\"\n",
    "\n",
    "    Then the answer in one sentence:\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test analyze chain\n",
    "chain = LLMChain(llm=llm, prompt=analyze_prompt, verbose=False)\n",
    "answer = chain.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10'"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a query that should error\n",
    "bad_query = 'SELECT count(a) FROM head'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Error: (sqlite3.OperationalError) no such column: a\\n[SQL: SELECT count(a) FROM head]\\n(Background on this error at: https://sqlalche.me/e/20/e3q8)'"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_error = db.run_no_throw(bad_query)\n",
    "\n",
    "query_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create query that should return a null avlue\n",
    "empty_query = \"SELECT name FROM head WHERE head_id = '25'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[]'"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_empty = db.run_no_throw(empty_query)\n",
    "\n",
    "test_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create prompt for debugging error\n",
    "debug_error_prompt = PromptTemplate(\n",
    "    input_variables=[],\n",
    "    template = f\"\"\"{bad_query}\n",
    "\n",
    "The query above produced the following error:\n",
    "\n",
    "{query_error}\n",
    "\n",
    "Rewrite the query with the error fixed:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create prompt for debugging error\n",
    "debug_empty_prompt = PromptTemplate(\n",
    "    input_variables=[],\n",
    "    template = f\"\"\"{empty_query}\n",
    "\n",
    "The query above produced no result. Try rewriting the query so it will return results to this question \"{question}\":\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSELECT count(a) FROM head\n",
      "\n",
      "The query above produced the following error:\n",
      "\n",
      "Error: (sqlite3.OperationalError) no such column: a\n",
      "[SQL: SELECT count(a) FROM head]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "\n",
      "Rewrite the query with the error fixed:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#test debug\n",
    "chain = LLMChain(llm=llm, prompt=debug_error_prompt, verbose=True)\n",
    "debugged = chain.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT count(*) FROM head'"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debugged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSELECT name FROM head WHERE head_id = '25'\n",
      "\n",
      "The query above produced no result. Try rewriting the query so it will return results to this question \"How many rows in the 'head' table in the 'department_management' schema?\":\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#test empty debug\n",
    "chain = LLMChain(llm=llm, prompt=debug_empty_prompt, verbose=True)\n",
    "emp_debugged = chain.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT Count ( * ) FROM head'"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_debugged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Full Loop for this Running and Debugging Process\n",
    "\n",
    "I want to have it take the output of the create sql statement step and then run it. If it returns any issues, try debugging 3 times. If none of those work, return a scripted error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish unique chains\n",
    "analyze_chain = LLMChain(llm=llm, prompt=analyze_prompt, verbose=False)\n",
    "\n",
    "debug_error_chain = LLMChain(llm=llm, prompt=debug_error_prompt, verbose=False)\n",
    "\n",
    "debug_empty_chain = LLMChain(llm=llm, prompt=debug_empty_prompt, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_and_run(max_attempts=3, sql_query=validated_query):\n",
    "    max_att = max_attempts\n",
    "    sql = sql_query\n",
    "\n",
    "    for attempt in range(1, max_att + 1):\n",
    "        query_result = db.run_no_throw(sql)\n",
    "\n",
    "        if query_result[:5] == 'Error':\n",
    "            if attempt == max_att:\n",
    "                output = f\"Unable to execute the SQL query after {max_att} attempts.\"\n",
    "                break\n",
    "\n",
    "            sql = debug_error_chain.predict()\n",
    "            time.sleep(1)  # Add a delay of 1 second between attempts\n",
    "        elif query_result == '[]':\n",
    "            if attempt == max_att:\n",
    "                output = \"Query returned no results after multiple attempts.\"\n",
    "                break\n",
    "\n",
    "            sql = debug_empty_chain.predict()\n",
    "            time.sleep(1)  # Add a delay of 1 second between attempts\n",
    "        else:\n",
    "            query_result = analyze_chain.predict()\n",
    "            output = f\"\"\"\n",
    "            Input question: {question}\n",
    "            SQL Query: {sql}\n",
    "            Answer: {query_result}\"\"\"\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agent\n",
    "\n",
    "https://python.langchain.com/docs/modules/agents/\n",
    "\n",
    "Two types ->\n",
    "- Action: at each step, decide on the next action using the outputs of the previous steps\n",
    "- Plan & Execute: decide on the full sequence up front, then execute them all without updating the plan\n",
    "\n",
    "Plan & Execute is better for larger problems because it maintains focus. Often it's best to combine and let P&E agents use action agents to execute plans.\n",
    "\n",
    "Tools -> actions an agent can take\n",
    "Toolkit -> wrapper around collections of tools for specifc use cases. Will need this for sql, tool to inspect tables and tool to run queries.\n",
    "\n",
    "#### Action Agents\n",
    "\n",
    "Wrapped in agent executors - call the agent, get back an action and action input, call the referenced tool, take the output of it and return it back to the agent.\n",
    "\n",
    "Typically has a prompt template, language model, and output parser\n",
    "\n",
    "#### Plan-and-Execute Agents\n",
    "\n",
    "Typically have the language model be the planner and the executor be an action agent.\n",
    "\n",
    "#### Built-In Agent Observations\n",
    "\n",
    "It appears the built-in model using an action agent - I'll try to tweak it. Maybe even by splitting out the steps into agents and trying the combo type with a larger plan & execute operating triggering the action agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType, load_tools, create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Toolkit\n",
    "\n",
    "I'll use the standard langchain one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Prompt Template - Create SQL Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_prompt = PromptTemplate(\n",
    "    input_variables={\"tool_names\"},\n",
    "    template=\"\"\"\n",
    "        Use the following format:\n",
    "        Question: the input question you must answer\n",
    "        Thought: you should always think about what to do\n",
    "        Action: the action to take, should be one of [{tool_names}]\n",
    "        Action Input: the input to the action\n",
    "        Observation: the result of the action\n",
    "        Thought: I now know the final answer\n",
    "        Final Answer: SQL query ONLY, always include columns \"Indexes\", \"Index_Name\" along with your final answer. \n",
    "        If column name is a reserve word add quotes around it\n",
    "        \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_exec = create_sql_agent(llm=llm,\n",
    "                                toolkit=toolkit,\n",
    "                                verbose=True,\n",
    "                                format_instructions=create_prompt,\n",
    "                                top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: sql_db_query\n",
      "Action Input: \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: \n",
      "\n",
      "SELECT COUNT(*) FROM department WHERE age\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How many heads of the departments are older than 56?',\n",
       " 'output': 'SELECT COUNT(*) FROM department WHERE age'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_exec(\"How many heads of the departments are older than 56?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Prompt Template - Check the SQL Query\n",
    "\n",
    "From here: https://canvasapp.com/blog/text-to-sql-in-production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"sql_dialect\", \"current_day\", \"sql\"],\n",
    "    template=\"\"\"\n",
    "        You are a helpful AI that verifies that a SQL query runs correctly. If the query does not run successfully, you iteratively update the query based on the error message.\n",
    "        You follow the following procedure:\n",
    "            1. Run the input SQL query using the QueryTool\n",
    "            2. If this runs successfully, return immediately.\n",
    "            3. If the SQL query fails, debug the query:\n",
    "                3a. consider the error message\n",
    "                3b. update the SOL query\n",
    "                3c. try re-running\n",
    "            4. Repeat step 3 until you have a valid result. Finish and exit with the updated SQL query.\n",
    "        You are writing SQL for the {sql_dialect} dialect.\n",
    "        The current day is {current_day} in case the user references the date\n",
    "        The user's original question: {question}\n",
    "        The SQL: {sql}\n",
    "        Begin!\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sql' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m formatted_prompt \u001b[39m=\u001b[39m prompt\u001b[39m.\u001b[39mformat(\n\u001b[1;32m      2\u001b[0m     question\u001b[39m=\u001b[39mquestion,\n\u001b[0;32m----> 3\u001b[0m     sql\u001b[39m=\u001b[39msql,\n\u001b[1;32m      4\u001b[0m     sql_dialect\u001b[39m=\u001b[39msql_dialect,\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sql' is not defined"
     ]
    }
   ],
   "source": [
    "formatted_prompt = prompt.format(\n",
    "    question=question,\n",
    "    sql=sql, #feed in an sql from a prior step?\n",
    "    sql_dialect=sql_dialect,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text2sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
