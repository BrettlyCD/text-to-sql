{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Agent\n",
    "\n",
    "I had limited success with the built-in functions, so I'll test a custom flow, really a combination of tweaked langchain functions.\n",
    "\n",
    "I think part of this could be more specialized schema and table extraction, but for now I think I'll stick with my single schema example and try to expand later.\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain import HuggingFaceHub, SQLDatabase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup query\n",
    "We'll use this to input into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How many heads of the departments are older than 56?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Target Tables from Vectordb\n",
    "\n",
    "Load in the top 3 results and save just the unique schemas to a set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup embeddings using HuggingFace and the directory location\n",
    "embeddings  = HuggingFaceEmbeddings()\n",
    "persist_dir = '../data/processed/chromadb/schema-table-split'\n",
    "\n",
    "# load from disk\n",
    "vectordb = Chroma(persist_directory=persist_dir, embedding_function=embeddings)\n",
    "\n",
    "#run similarity search\n",
    "top_results = vectordb.similarity_search(question, k=3) #just return the top for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'department_management'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_targets[0].metadata['schema']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Target Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'department_management', 'hr_1'}\n"
     ]
    }
   ],
   "source": [
    "target_schemas = set()\n",
    "for doc in top_targets:\n",
    "    schema = doc.metadata['schema']\n",
    "    target_schemas.add(schema)\n",
    "\n",
    "print(target_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'department_management'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(target_schemas)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool - Query for Schema Information\n",
    "Use the langchain SQLDatabase class to get all the information about the schema. I think I also want to use the most likely columns returned to sort and prioritize how the tables are fed into the llm.\n",
    "\n",
    "#### Point to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_filepath = '../data/processed/db/'\n",
    "db_filename = list(target_schemas)[0] + '.sqlite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#point to database\n",
    "base_dir = os.path.dirname(os.path.abspath(db_filepath+db_filename)) #get the full path within the device\n",
    "db_path = os.path.join(base_dir, db_filename) #combine with filename to get db_path\n",
    "db = SQLDatabase.from_uri(\"sqlite:///\" + db_path) #connect via the lanchain method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set table sorting and then pull tables names using langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['head', 'department']\n"
     ]
    }
   ],
   "source": [
    "#pull the table names from the vector query so we can have them in order of similarity to the question.\n",
    "table_sorting = set()\n",
    "for doc in top_targets:\n",
    "    schema = doc.metadata['schema']\n",
    "    if schema == 'department_management':\n",
    "        table_name = doc.metadata['table']\n",
    "        table_sorting.add(table_name)\n",
    "table_sorting = list(table_sorting)\n",
    "print(table_sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['head', 'department', 'management']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get tables names\n",
    "table_names = db.get_usable_table_names()\n",
    "\n",
    "#sort by the results of our vector query to load the most likely table in first. Not sure if this will make a difference, but can't imagine it would hurt.\n",
    "priority_tables = sorted(table_names, key=lambda x: (table_sorting.index(x) if x in table_sorting else float('inf'), table_names.index(x)))\n",
    "\n",
    "priority_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get SQL Dialect\n",
    "\n",
    "Using the langchain class again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sqlite'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_dialect = db.dialect\n",
    "\n",
    "sql_dialect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get table info\n",
    "\n",
    "You can do this for all tables in the database automatically with the function, but I want to continue trying to order these by likelihood of being related to the question. So I'll do this in a loop.\n",
    "\n",
    "This gives the full create statement and 3 sample rows, which I think will be a great start. And really gets us to where the Chain does for adding to the prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['head']\n",
      "['department']\n",
      "['management']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\nCREATE TABLE head (\\n\\t\"head_ID\" INTEGER, \\n\\tname TEXT, \\n\\tborn_state TEXT, \\n\\tage REAL, \\n\\tPRIMARY KEY (\"head_ID\")\\n)\\n\\n/*\\n3 rows from head table:\\nhead_ID\\tname\\tborn_state\\tage\\n1\\tTiger Woods\\tAlabama\\t67.0\\n2\\tSergio GarcÃ­a\\tCalifornia\\t68.0\\n3\\tK. J. Choi\\tAlabama\\t69.0\\n*/',\n",
       " '\\nCREATE TABLE department (\\n\\t\"Department_ID\" INTEGER, \\n\\t\"Name\" TEXT, \\n\\t\"Creation\" TEXT, \\n\\t\"Ranking\" INTEGER, \\n\\t\"Budget_in_Billions\" REAL, \\n\\t\"Num_Employees\" REAL, \\n\\tPRIMARY KEY (\"Department_ID\")\\n)\\n\\n/*\\n3 rows from department table:\\nDepartment_ID\\tName\\tCreation\\tRanking\\tBudget_in_Billions\\tNum_Employees\\n1\\tState\\t1789\\t1\\t9.96\\t30266.0\\n2\\tTreasury\\t1789\\t2\\t11.1\\t115897.0\\n3\\tDefense\\t1947\\t3\\t439.3\\t3000000.0\\n*/',\n",
       " '\\nCREATE TABLE management (\\n\\t\"department_ID\" INTEGER, \\n\\t\"head_ID\" INTEGER, \\n\\ttemporary_acting TEXT, \\n\\tPRIMARY KEY (\"department_ID\", \"head_ID\"), \\n\\tFOREIGN KEY(\"head_ID\") REFERENCES head (\"head_ID\"), \\n\\tFOREIGN KEY(\"department_ID\") REFERENCES department (\"Department_ID\")\\n)\\n\\n/*\\n3 rows from management table:\\ndepartment_ID\\thead_ID\\ttemporary_acting\\n2\\t5\\tYes\\n15\\t4\\tYes\\n2\\t6\\tYes\\n*/']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_info = []\n",
    "for table in priority_tables:\n",
    "    info = db.get_table_info(table_names=[table])\n",
    "    table_info.append(info)\n",
    "\n",
    "table_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.dirname(os.path.abspath('../data/processed/db/'+top_schema+'.sqlite'))\n",
    "db_path = os.path.join(BASE_DIR, \"department_management.sqlite\")\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///\" + db_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup LLM\n",
    "I'll continue to use the falcon-7b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get api key\n",
    "load_dotenv()\n",
    "hf_api_token = os.getenv('hf_token')\n",
    "\n",
    "#add path to HF repo\n",
    "repo_id = 'tiiuae/falcon-7b-instruct'\n",
    "\n",
    "#establish llm model\n",
    "llm = HuggingFaceHub(repo_id=repo_id, huggingfacehub_api_token=hf_api_token, model_kwargs={\"temperature\": 0.5, \"max_length\": 8000})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agent\n",
    "\n",
    "https://python.langchain.com/docs/modules/agents/\n",
    "\n",
    "Two types ->\n",
    "- Action: at each step, decide on the next action using the outputs of the previous steps\n",
    "- Plan & Execute: decide on the full sequence up front, then execute them all without updating the plan\n",
    "\n",
    "Plan & Execute is better for larger problems because it maintains focus. Often it's best to combine and let P&E agents use action agents to execute plans.\n",
    "\n",
    "Tools -> actions an agent can take\n",
    "Toolkit -> wrapper around collections of tools for specifc use cases. Will need this for sql, tool to inspect tables and tool to run queries.\n",
    "\n",
    "#### Action Agents\n",
    "\n",
    "Wrapped in agent executors - call the agent, get back an action and action input, call the referenced tool, take the output of it and return it back to the agent.\n",
    "\n",
    "Typically has a prompt template, language model, and output parser\n",
    "\n",
    "#### Plan-and-Execute Agents\n",
    "\n",
    "Typically have the language model be the planner and the executor be an action agent.\n",
    "\n",
    "#### Built-In Agent Observations\n",
    "\n",
    "It appears the built-in model using an action agent - I'll try to tweak it. Maybe even by splitting out the steps into agents and trying the combo type with a larger plan & execute operating triggering the action agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType, load_tools, create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Toolkit\n",
    "\n",
    "I'll use the standard langchain one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Prompt Template - Create SQL Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_prompt = PromptTemplate(\n",
    "    input_variables={\"tool_names\"},\n",
    "    template=\"\"\"\n",
    "        Use the following format:\n",
    "        Question: the input question you must answer\n",
    "        Thought: you should always think about what to do\n",
    "        Action: the action to take, should be one of [{tool_names}]\n",
    "        Action Input: the input to the action\n",
    "        Observation: the result of the action\n",
    "        Thought: I now know the final answer\n",
    "        Final Answer: SQL query ONLY, always include columns \"Indexes\", \"Index_Name\" along with your final answer. \n",
    "        If column name is a reserve word add quotes around it\n",
    "        \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_exec = create_sql_agent(llm=llm,\n",
    "                                toolkit=toolkit,\n",
    "                                verbose=True,\n",
    "                                format_instructions=create_prompt,\n",
    "                                top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: sql_db_query\n",
      "Action Input: \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: \n",
      "\n",
      "SELECT COUNT(*) FROM department WHERE age\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How many heads of the departments are older than 56?',\n",
       " 'output': 'SELECT COUNT(*) FROM department WHERE age'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_exec(\"How many heads of the departments are older than 56?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Prompt Template - Check the SQL Query\n",
    "\n",
    "From here: https://canvasapp.com/blog/text-to-sql-in-production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"sql_dialect\", \"current_day\", \"sql\"],\n",
    "    template=\"\"\"\n",
    "        You are a helpful AI that verifies that a SQL query runs correctly. If the query does not run successfully, you iteratively update the query based on the error message.\n",
    "        You follow the following procedure:\n",
    "            1. Run the input SQL query using the QueryTool\n",
    "            2. If this runs successfully, return immediately.\n",
    "            3. If the SQL query fails, debug the query:\n",
    "                3a. consider the error message\n",
    "                3b. update the SOL query\n",
    "                3c. try re-running\n",
    "            4. Repeat step 3 until you have a valid result. Finish and exit with the updated SQL query.\n",
    "        You are writing SQL for the {sql_dialect} dialect.\n",
    "        The current day is {current_day} in case the user references the date\n",
    "        The user's original question: {question}\n",
    "        The SQL: {sql}\n",
    "        Begin!\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sql' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m formatted_prompt \u001b[39m=\u001b[39m prompt\u001b[39m.\u001b[39mformat(\n\u001b[1;32m      2\u001b[0m     question\u001b[39m=\u001b[39mquestion,\n\u001b[0;32m----> 3\u001b[0m     sql\u001b[39m=\u001b[39msql,\n\u001b[1;32m      4\u001b[0m     sql_dialect\u001b[39m=\u001b[39msql_dialect,\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sql' is not defined"
     ]
    }
   ],
   "source": [
    "formatted_prompt = prompt.format(\n",
    "    question=question,\n",
    "    sql=sql, #feed in an sql from a prior step?\n",
    "    sql_dialect=sql_dialect,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text2sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
