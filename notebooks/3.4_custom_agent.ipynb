{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Agent\n",
    "\n",
    "I had limited success with the built-in functions, so I'll test a custom flow, really a combination of tweaked langchain functions.\n",
    "\n",
    "I think part of this could be more specialized schema and table extraction, but for now I think I'll stick with my single schema example and try to expand later.\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain import HuggingFaceHub, SQLDatabase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup query\n",
    "We'll use this to input into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How many heads of the departments are older than 56?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Target Tablor from Vectordb\n",
    "\n",
    "I could just point to it, but I do want to make sure this whole flow works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup embeddings using HuggingFace and the directory location\n",
    "embeddings  = HuggingFaceEmbeddings()\n",
    "persist_dir = '../data/processed/chromadb/schema-table-split'\n",
    "\n",
    "# load from disk\n",
    "vectordb = Chroma(persist_directory=persist_dir, embedding_function=embeddings)\n",
    "\n",
    "#run similarity search\n",
    "top_target = vectordb.similarity_search(question, k=1) #just return the top for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "department_management head [\"head_id\", \"name\", \"born_state\", \"age\"]\n"
     ]
    }
   ],
   "source": [
    "# Create variables\n",
    "top_schema = top_target[0].metadata['schema']\n",
    "top_table = top_target[0].metadata['table']\n",
    "table_cols = top_target[0].metadata['columns']\n",
    "\n",
    "print(top_schema, top_table, table_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.dirname(os.path.abspath('../data/processed/db/'+top_schema+'.sqlite'))\n",
    "db_path = os.path.join(BASE_DIR, \"department_management.sqlite\")\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///\" + db_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup LLM\n",
    "I'll continue to use the falcon-7b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get api key\n",
    "load_dotenv()\n",
    "hf_api_token = os.getenv('hf_token')\n",
    "\n",
    "#add path to HF repo\n",
    "repo_id = 'tiiuae/falcon-7b-instruct'\n",
    "\n",
    "#establish llm model\n",
    "llm = HuggingFaceHub(repo_id=repo_id, huggingfacehub_api_token=hf_api_token, model_kwargs={\"temperature\": 0.5, \"max_length\": 1500})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agent\n",
    "\n",
    "https://python.langchain.com/docs/modules/agents/\n",
    "\n",
    "Two types ->\n",
    "- Action: at each step, decide on the next action using the outputs of the previous steps\n",
    "- Plan & Execute: decide on the full sequence up front, then execute them all without updating the plan\n",
    "\n",
    "Plan & Execute is better for larger problems because it maintains focus. Often it's best to combine and let P&E agents use action agents to execute plans.\n",
    "\n",
    "Tools -> actions an agent can take\n",
    "Toolkit -> wrapper around collections of tools for specifc use cases. Will need this for sql, tool to inspect tables and tool to run queries.\n",
    "\n",
    "#### Action Agents\n",
    "\n",
    "Wrapped in agent executors - call the agent, get back an action and action input, call the referenced tool, take the output of it and return it back to the agent.\n",
    "\n",
    "Typically has a prompt template, language model, and output parser\n",
    "\n",
    "#### Plan-and-Execute Agents\n",
    "\n",
    "Typically have the language model be the planner and the executor be an action agent.\n",
    "\n",
    "#### Built-In Agent Observations\n",
    "\n",
    "It appears the built-in model using an action agent - I'll try to tweak it. Maybe even by splitting out the steps into agents and trying the combo type with a larger plan & execute operating triggering the action agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType, load_tools\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Toolkit\n",
    "\n",
    "I'll use the standard langchain one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Prompt Template - Create SQL Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Prompt Template - Check the SQL Query\n",
    "\n",
    "From here: https://canvasapp.com/blog/text-to-sql-in-production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"sql_dialect\", \"current_day\", \"sql\"],\n",
    "    template=\"\"\"\n",
    "        You are a helpful AI that verifies that a SQL query runs correctly. If the query does not run successfully, you iteratively update the query based on the error message.\n",
    "        You follow the following procedure:\n",
    "            1. Run the input SQL query using the QueryTool\n",
    "            2. If this runs successfully, return immediately.\n",
    "            3. If the SQL query fails, debug the query:\n",
    "                3a. consider the error message\n",
    "                3b. update the SOL query\n",
    "                3c. try re-running\n",
    "            4. Repeat step 3 until you have a valid result. Finish and exit with the updated SQL query.\n",
    "        You are writing SQL for the {sql_dialect} dialect.\n",
    "        The current day is {current_day} in case the user references the date\n",
    "        The user's original question: {question}\n",
    "        The SQL: {sql}\n",
    "        Begin!\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sql' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m formatted_prompt \u001b[39m=\u001b[39m prompt\u001b[39m.\u001b[39mformat(\n\u001b[1;32m      2\u001b[0m     question\u001b[39m=\u001b[39mquestion,\n\u001b[0;32m----> 3\u001b[0m     sql\u001b[39m=\u001b[39msql,\n\u001b[1;32m      4\u001b[0m     sql_dialect\u001b[39m=\u001b[39msql_dialect,\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sql' is not defined"
     ]
    }
   ],
   "source": [
    "formatted_prompt = prompt.format(\n",
    "    question=question,\n",
    "    sql=sql,\n",
    "    sql_dialect=sql_dialect,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'toolkit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m agent \u001b[39m=\u001b[39m initialize_agent(toolkit\u001b[39m.\u001b[39mget_query_tools(), llm, agent\u001b[39m=\u001b[39mAgentType\u001b[39m.\u001b[39mZERO_SHOT_REACT_DESCRIPTION,)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'toolkit' is not defined"
     ]
    }
   ],
   "source": [
    "agent = initialize_agent(toolkit.get_query_tools(), llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text2sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
